Pacific herring genome
===
_Coding notes_

Nov 17, 2017
---

* Downloading data from Tony's account using wget

* downloaded supernova as per website description and ran sitecheck and testrun

Nov 21, 2017
---

* Downloaded trimmomatic-0.36 in the program subfolder
* Starting to trim the original raw reads

Nov 22 2017
---

* Finished trimming - statistics can be found in ```/scripts/trim/phgenome_trim.output```

* Started fastqc (version 0.11) to look at the quality of output

* FastQC looks fine, but files are unrecognizeable by supernova after trimming. Thus, I will assemble using raw reads.

* Started assembly with supernova (script in /scirpts/assembly/ directory)

Nov 29 2017
---

* Starting run of the assembly on Mike Miller's bigmem node

```srun -A millermrgrp -p bigmemh -t 5 hostname```

Nov-Feb
---
* Ran supernova assembly on XSEDE cluster because it had 2TB Ram. Code for assembly was

```
/pylon5/bi4ifup/eoziolor/program/supernova-2.0.0/supernova-cs/2.0.0/bin/run \
--id phgenome3 \
--maxreads 340000000 \
--fastqs /pylon5/bi4ifup/eoziolor/phgenome/data/raw/ \
--localcores=28 
```

Feb 12 2018
---

* Downloaded phgenome3 (assembly with 56x coverage) of Pacific herring genome
* Used mkoutput to create a fasta file with bubble information in it (megabubble). Found in 
```
#!/bin/bash

#SBATCH -J fastagen
#SBATCH -o /home/eoziolor/phgenome/scripts/fasta/phg_fasta_%j.o
#SBATCH -e /home/eoziolor/phgenome/scripts/fasta/phg_fasta_%j.o
#SBATCH --time=7-00:00
#SBATCH --mem=60000

my_super=/home/eoziolor/program/supernova-2.0.0/supernova
my_out=/home/eoziolor/phgenome/data/assembly3/outs/assembly
my_fasta=/home/eoziolor/phgenome/data/assembly3/fasta/phgenome

$my_super mkoutput \
--asmdir=$my_out \
--outprefix=$my_fasta \
--style=megabubbles \
--headers=full
```

Feb 27, 2018
---

* converted .gz to .bgz with bgzip
* indexing genome to find true size of assembly including smaller scaffolds

Mar 30, 2018
---

* Subsetted the genome using cat of the number of reads we need divided by 2 for each of the R1 and R2.
* Number of reads calculated by coverage for the following:
55x - 340 000 000
70x - 433 000 000
85x - 526 000 000
100x - 618 000 000
128x - 771 607 516

* Then I concatenate the resulting files and run custom python script on them to determine # of unique kmers
    * did not work, but I am moving onto the ARKS pathway

Apr 20 2018
---

* used anaconda3 module: module load anaconda3

* created an environment in phgenome:
```
conda create -n phgenome python=3.6
```

* should activate with: 

```
source activate phgenome
```

* Need to install pip in the environment (otherwise it uses global pip)

```
conda install -n phgenome pip
```

Jun 18 2018
--------
### Re-scaffolding genome
* Going to use the [ARKS pipeline](https://github.com/bcgsc/arks) to create a better assembly from the simple (pseudohaploid) fasta that I created:

```
#!/bin/bash

#SBATCH -J fastagen
#SBATCH -o /home/eoziolor/phgenome/scripts/fasta/phg_fasta_%j.o
#SBATCH -e /home/eoziolor/phgenome/scripts/fasta/phg_fasta_%j.o
#SBATCH --time=0-01:00
#SBATCH --mem=60000

my_super=/home/eoziolor/program/supernova-2.0.0/supernova
my_out=/home/eoziolor/phgenome/data/assembly3/outs/assembly
my_fasta=/home/eoziolor/phgenome/data/assembly3/fasta/phgenome

$my_super mkoutput \
--asmdir=$my_out \
--outprefix=$my_fasta \
--style=pseudohap \
--headers=full
```
* Plus interleaved read file containing all of the reads I have
* trying long ranger basic for filtering and creating a bam file out of the fastqs

```
#!/bin/bash -l
#SBATCH -J longbasic
#SBATCH -o longbasic-%j.o
#SBATCH -e longbasic-%j.o
#SBATCH -N 1
#SBATCH -n 8
#SBATCH --time=1-00:00
#SBATCH --mem=60000
#SBATCH --no-requeue
#SBATCH -p high

#programs and files
long=/home/eoziolor/program/longranger-2.2.2/longranger
path=/home/eoziolor/phgenome/data/raw/
id=PH-Sitka-93_S1_L008

cd /home/eoziolor/phgenome/data/raw/
#code
$long basic \
--id=$id \
--fastqs=$path \
--bam
```

* Found out that ARKS only takes FASTQ interleaved files; using longranger basic to do that:

```
#!/bin/bash -l
#SBATCH -J fastqbasic
#SBATCH -o fastqbasic-%j.o
#SBATCH -e fastqbasic-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --time=2-00:00
#SBATCH --mem=60000
#SBATCH --no-requeue
#SBATCH -p high

#programs and files
long=/home/eoziolor/program/longranger-2.2.2/longranger
path=/home/eoziolor/phgenome/data/raw/
id=NewFastq

cd /home/eoziolor/phgenome/data/raw/
#code
$long basic \
--id=$id \
--fastqs=$path
```

Jul 23 2018
--------
* Links is having issues with the python5 environment when trying to create a BloomFilt
    * I silenced the following lines from the LINKS run file:

```
#use lib "$FindBin::Bin/./lib/bloomfilter/swig";
#use BloomFilter;
```
* as per recommendation from the author, since I am only using links with ARKS

https://github.com/bcgsc/LINKS/issues/15

### SUPER IMPORTANT #2 of the day

* I added:

```
SHELL := /bin/bash
```

* and created a new arks-make file, now called arks-make2. This defintes the shell script for the file to be bash rather than sh. sh has an issue:
* it doesn't recognize "|$" to place standard error in a file, so I'm testing it out.

Jul 24, 2018
---
* Waiting for the fastq interleaved file to be created - it takes forever!

## Genome annotation
* in the meantime I will install the software from the steps outlined [here](https://uswest.ensembl.org/Astyanax_mexicanus/Info/Annotation) to begin annotation as soon as I have a better genome

### Repeat masker installation

* Downloading and installing the dependency RMBlast Source Package and Patch File

```
curl -O ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/2.6.0/ncbi-blast-2.6.0+-src.tar.gz
curl -O http://www.repeatmasker.org/isb-2.6.0+-changes-vers2.patch.gz

tar -zxvf ncbi-blast-2.6.0+-src.tar.gz
gunzip isb-2.6.0+-changes-vers2.patch.gz

cd ncbi-blast-2.6.0+-src
patch -p1 < ../isb-2.6.0+-changes-vers2.patch

cd c++
./configure --with-mt --prefix=/home/eoziolor/program/ncbi-blast-2.6.0+-src/ --without-debug
make
make install
```
This last step takes FOREVER!

* Throws an error, so I'll try installing without the patch.




* Downloaded Tandem Repeats Finder from [here](http://tandem.bu.edu/trf/trf409.linux64.download.html)
* moved it to farm with

```
scp -P 2022 ~/Downloads/trf409.linux64 farm:/home/eoziolor/program/
```

July 25, 2018
---
## Genome re-assembly
* Finally the interleaved fastq file was created
* Now I just need to run arks-make2 in order to try and run this pipeline
    * the stupid pipeline doesn't run with a gzipped file
```
gzip phgenome.hap.fasta.gz > phgenome.hap.fa
```


* Created links to the files into the same directory because the program needs to be run from one directory with the files.

```
ln -s /home/eoziolor/phgenome/data/assembly3/fasta/phgenome.hap.fa /home/eoziolor/phgenome/data/arks/
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/arks/
```

* First attempt at running the arks script

```
#!/bin/bash -l

#SBATCH -J runarks
#SBATCH -o runarks-%j.o
#SBATCH -e runarks-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=2-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/arks/

#files
my_fasta=phgenome.hap
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-6000 \
a=0.9 \
o=3 \
threads=16 
```

## Genome annotation
* So the RMBlast package is just not working out for installation, I will try another of the 4 packages
* Starting with HMMER:
    * installation

```
wget http://eddylab.org/software/hmmer/hmmer-3.2.1.tar.gz
tar xf hmmer-3.2.1.tar.gz
cd hmmer-3.2.1
./configure --prefix=/home/eoziolor/program/hmmer-3.2.1
make
make check
```
* Well that was freaking fantastic. Worked like butter on toast. Ok sticking with HMMER for the dependency search engine for RepeatMasker
    * added a path to ~/.bashrc to make these executed by name

```
export PATH=/home/eoziolor/program/hmmer-3.2.1/src:$PATH
```

* Ok, it's time to download and install RepeatMasker itself:

```
curl -O http://www.repeatmasker.org/RepeatMasker-open-4-0-7.tar.gz
tar -xvzf RepeatMasker-open-4-0-7.tar.gz 
```

* I registered for the RepeatMasker edition of RepBase. Once I have it, I can put the library into the RepeatMasker/Libraries folder
* Checking for updates of Dfam-hmm.gz - none
* Configure the RepeatMasker program - reconfigure after you add any library

```
cd RepeatMasker
perl ./configure
```

* RepeatMasker successfully installed with configured Hmmer as search engine
* Got registration permission for RepBase: download to computer and then install

```
cd /home/eoziolor/program/RepeatMasker
tar xvzf RepBaseRepeatMaskerEdition-20170127.tar.gz
```
* reconfigured with RepBase database included

### Beginning installation of RepeatModeler

#### Dependencies:
1. Perl - check
2. RepeatMasker + Libraries - check
3. RECON - De Novo Repeat Finder

```
curl -O http://www.repeatmasker.org/RepeatModeler/RECON-1.08.tar.gz
tar -xvzf RECON-1.08.tar.gz 
cd RECON-1.08/scripts/
nano recon.pl
# script "recon.pl" in the scripts directory -- on the third line, add
#the path to the binaries (the bin directory here) between the double quotes
#line: /home/eoziolor/program/RECON-1.08/bin/
cd ../src/
make
make install
```

4. RepeatScout - De Novo Repeat Finder, Price A.L., Jones N.C. and Pevzner P.A.

```
curl -O http://www.repeatmasker.org/RepeatScout-1.0.5.tar.gz
tar -xvzf RepeatScout-1.0.5.tar.gz
make
```
   
5. TRF - check

```
mv trf409.linux64 trf
```
* reconfigured RepeatMasker to work with this new file name instead with the old one

6. NSEG - Low complexity sequence identification

```
wget --no-parent -r ftp://ftp.ncbi.nih.gov/pub/seg/nseg
mv ftp.ncbi.nih.gov/pub/seg/nseg .
make
```
7. Search engine that I can't install...let's see if we can do this with HMMER

#### Installing RepeatModeler

```
curl -O http://www.repeatmasker.org/RepeatModeler/RepeatModeler-open-1.0.11.tar.gz
tar -xvzf RepeatModeler-open-1.0.11.tar.gz
cd RepeatModeler-open-1.0.11
#To load the latest 5.26 perl with JSON module do:
module load perl
perl ./configure
```
* guess what...the program doesn't work with HMMER...suprise surprise. Ok let's give RMBlast another go

* RMBlast - trying previous binaries 

```
curl -O ftp://ftp.ncbi.nlm.nih.gov/blast/executables/rmblast/2.2.28/ncbi-rmblastn-2.2.28-x64-linux.tar.gz
curl -O ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/2.2.28/ncbi-blast-2.2.28+-x64-linux.tar.gz

tar zxvf ncbi-blast-2.2.28+-x64-linux.tar.gz
tar zxvf ncbi-rmblastn-2.2.28-x64-linux.tar.gz

cp ncbi-rmblastn-2.2.28/* ncbi-blast-2.2.28+/
cp ncbi-rmblastn-2.2.28/bin/* ncbi-blast-2.2.28+/bin/

rm -rf ncbi-rmblastn-2.2.28
mv ncbi-blast-2.2.28+ rmblast-2.2.28
```

### Reconfiguring RepeatMasker before configuring RepeatModeler

```
module load perl

cd /home/eoziolor/program/RepeatMasker/
perl ./configure

cd /home/eoziolor/program/RepeatModeler-open-1.0.11/
perl ./configure
```
## Genome re-assembly cont'd

* Moving all of the output files into the akrs1 directory for the first iteration of the arks
* Starting second iterations

```
cd /home/eoziolor/phgenome/data/arks/
mkdir arks1
mv * akrs1
mkdir arks2
```

* creating symlinks to the necessary files

```
ln -s /home/eoziolor/phgenome/data/arks/arks1/phgenome.hap_c5_m50-6000_k30_r0.05_e30000_z500_l5_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/arks/arks2/arks1.fa

ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/arks/arks2/

```

* Running second iteration of ARKS = arks2
    * running with default parameters this time.

```
#!/bin/bash -l

#SBATCH -J runarks2
#SBATCH -o runarks2-%j.o
#SBATCH -e runarks2-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/arks/arks2/

#files
my_fasta=arks1
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.3 \
o=3 \
threads=16 
```

Jul 26, 2018
---

## Genome re-assembly
* second iteration of ARKS was less than exciting - 10kb increase in N50.
* About to try playing with parameters
    * See Supplementary table 4 for recommended ranges of parameters that are found acceptable by authors
* switching a from 0.3 to 0.9 (suggested in paper for larger max scaffold and n50 contiguity). That's the LINKS maximum link ratio
* leaving -e to 30000, to consider slightly longer contigs. Don't understand this parameter fully. Need to ask further. __Consider changing in future iterations__.
* dropping minimum number of read pairs with barcode from 5 to 4 (-c=3)
* since reads get thrown out for multiplicity range, I want to check why. Downloading multiplicity csv file to look at distribution
    * see code in R (combined.Rmd)
    * Turns out we have a bunch of reads that only have 1 pair with a barcode...super unhelpful for a large assembly
    * also makes it meaningless to change multiplicity range because the ones below 50 are pretty much lone pairs and there are non above 10 000 - Good to know!
* Moving p-value to 0.1 because 0.05 is a strange parameter anyways (r=0.1). Also paper suggests that this is acceptable.
* Moving links parameter l, to match the minimum number of pairs we specified to arks - 3 pairs for each node (l=3), paper suggests this as the minimum parameter.
* allowing LINKS to consider lower sequence length as well. Paper suggests 250 is ok, while default is 500 (z=250)



```
ln -s /home/eoziolor/phgenome/data/arks/arks2/arks1_c5_m50-10000_k30_r0.05_e30000_z500_l5_a0.3.scaffolds.fa /home/eoziolor/phgenome/data/arks/arks3/arks2.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/arks/arks3/
```

```
#!/bin/bash -l

#SBATCH -J runarks3
#SBATCH -o runarks3-%j.o
#SBATCH -e runarks3-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/arks/arks3/

#files
my_fasta=arks2
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
o=3 \
c=3 \
e=30000 \
r=0.1 \
l=3 \
z=250 \
threads=16 
```
* Find the ARKS paper [here](https://academic.oup.com/bioinformatics/article/34/5/725/4562503)

### ARKS run4

* Time to focus on some of the smaller contigs and bring them up: I will alter the e value down to 10000 in order to focus on the shorter contigs and try to re-stitch those together


```
ln -s /home/eoziolor/phgenome/data/arks/arks3/arks2_c3_m50-10000_k30_r0.1_e30000_z250_l3_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/arks/arks4/arks3.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/arks/arks4/
```

```
#!/bin/bash -l

#SBATCH -J runarks4
#SBATCH -o runarks4-%j.o
#SBATCH -e runarks4-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/arks/arks4/

#files
my_fasta=arks3
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
o=3 \
c=3 \
e=10000 \
r=0.1 \
l=3 \
z=250 \
threads=16 
```
### ARKS run5

* Let's alter the e parameter up slightly to fix some of the now bigger scaffolds e=20000


```
ln -s /home/eoziolor/phgenome/data/arks/arks4/arks3_c3_m50-10000_k30_r0.1_e10000_z250_l3_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/arks/arks5/arks4.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/arks/arks5/
```

```
#!/bin/bash -l

#SBATCH -J runarks5
#SBATCH -o runarks5-%j.o
#SBATCH -e runarks5-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/arks/arks5/

#files
my_fasta=arks4
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
o=3 \
c=3 \
e=20000 \
r=0.1 \
l=3 \
z=250 \
threads=16 
```

### ARKS run6

* Let's alter the e parameter up slightly to fix some of the now bigger scaffolds e=30000
* Returning the parameters to slightly more stringent.
* c=5;l=5;r=0.05


```
ln -s /home/eoziolor/phgenome/data/arks/arks5/arks4_c3_m50-10000_k30_r0.1_e20000_z250_l3_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/arks/arks6/arks5.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/arks/arks6/
```

```
#!/bin/bash -l

#SBATCH -J runarks6
#SBATCH -o runarks6-%j.o
#SBATCH -e runarks6-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/arks/arks6/

#files
my_fasta=arks5
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
o=3 \
c=5 \
e=30000 \
r=0.05 \
l=5 \
z=250 \
threads=16 
```

### ARKS run7

* Keeping stringent parameters, even though we only get about 100kb increase in N50 at a time, I think at this point that's necessary. When scaffolding the shorter fragments, it may be alright to relax them as in shorter scaffolds you get less read pairs to put them together.
* I want to go back in e value back to 10000 and focus on the small scaffolds. I will keep the rest of the values the same, to see the effect of just e.



```
ln -s /home/eoziolor/phgenome/data/arks/arks6/arks5_c5_m50-10000_k30_r0.05_e30000_z250_l5_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/arks/arks7/arks6.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/arks/arks7/
```

```
#!/bin/bash -l

#SBATCH -J runarks7
#SBATCH -o runarks7-%j.o
#SBATCH -e runarks7-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/arks/arks7/

#files
my_fasta=arks6
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
o=3 \
c=5 \
e=10000 \
r=0.05 \
l=5 \
z=250 \
threads=16 
```
## Genome re-assembly
### ARKS pipeline re-start

* Spoke to the author of the paper and he suggested that I run tigmint before the first iteration of the assembly, but run as I have from there on.
    * This is mostly to correct for any misassemblies that could have happened to the scaffolds in the initial supernova assembly
* Tigmint is already installed, just have to make sure that python3 is loaded when script starts
* Start by creating the symlinks in a new directory called tigarks

```
ln -s /home/eoziolor/phgenome/data/assembly3/fasta/phgenome.hap.fa /home/eoziolor/phgenome/data/tigarks/arks1/supernova.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks1/
```
* Now let's run arks
    * putting parameters as relatively stringent
    * adding kmer size of 42 due to Titus recommendations
    * Let's see how it goes

```
#!/bin/bash -l

#SBATCH -J runarks1
#SBATCH -o runarks1-%j.o
#SBATCH -e runarks1-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

module load python3
source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks1/

#files
my_fasta=supernova
my_reads=barcoded

#code
arks-make2 arks-tigmint \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=5 \
e=10000 \
r=0.05 \
l=5 \
z=250 \
k=42 \
threads=16 \
t=16
```
July 28, 2018
===

* So the Tigmint has been failing at creating a new .bam file because for some reason the script of samtools is forcing it to write into a /tmp directory. I will try to run that script separately, altered for directory, and then feed tigmint the bamfile.

```
#!/bin/bash -l

#SBATCH -J bamcreate
#SBATCH -o bamcreate-%j.o
#SBATCH -e bamcreate-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=2-00:00
#SBATCH --no-requeue
#SBATCH -p high

module load python3
source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks1/

#files
my_fasta=supernova
my_reads=barcoded

#code
bwa mem -t16 -pC supernova.fa barcoded.fq.gz |\
samtools view -u -F4 |\
samtools sort -@16 -tBX \
-o supernova.barcoded.sortbx.bam
```

July 30, 2018
===
* So the script for bwa and samtools to create a barcoded aligned .bam worked just fine. I am copying it to another directory (just in case). Now I will run the tigmint+arks pipeline, hoping it will recognize the bam and not try to recreate it again.

* I am having issues with tigmint-molecule loading pysam from the general environment rather than the pysam that I want it to. This is why I am running that line separately and loading the bio3 environment which has a pysam that is dependent on python3, not the python2 old version of pysam that is on the general module list

```
#!/bin/bash -l

#SBATCH -J molecule
#SBATCH -o molecule-%j.o
#SBATCH -e molecule-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

module load bio3

cd /home/eoziolor/phgenome/data/tigarks/arks1/

#files
my_bam=supernova.barcoded.sortbx.bam
my_reads=barcoded
my_tigm=/home/eoziolor/program/tigmint/bin/tigmint-molecule

#code
$my_tigm $my_bam | sort -k1,1 -k2,2n -k3,3n >supernova.reads.molecule.bed
```
* this works just fine. Now I will finish off the process with:

```
 #!/bin/bash -l

#SBATCH -J runarks1
#SBATCH -o runarks1-%j.o
#SBATCH -e runarks1-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=2-00:00
#SBATCH --no-requeue
#SBATCH -p high

#source ~/.bashrc
export PATH=/home/eoziolor/program/tigmint/bin:$PATH
export PATH=/home/eoziolor/program/arks/Examples:$PATH
export PATH=/home/eoziolor/program/arks/Arks:$PATH
module load bio3

cd /home/eoziolor/phgenome/data/tigarks/arks1/

#files
my_fasta=supernova
my_reads=barcoded

#code
arks-make2 arks-tigmint \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=5 \
e=10000 \
r=0.05 \
l=5 \
z=250 \
k=42 \
threads=16 \
t=16
```

* I can probably run this last bit isntead of all the middle parts. Oh well, for the next iterations I'll only have to run arks without tigmint.


* Ok, there's more dependencies that I need for this, so I'm just going to install conda and run from there

```
module load conda3
conda create -n phgenome
source activate phgenome

conda config --add channels r
conda config --add channels bioconda

conda install pysam
conda install -c bioconda pybedtools
conda install -c conda-forge intervaltree
conda install -c conda-forge statistics 
conda install cython
conda install -c bioconda bedtools htslib
```

* Trying new environment
```
conda create -n pybed_phgenome -c daler pybedtools bedtools python=3
```

* Ok so initially that didn't work because it was giving me issues with __init__.py. So I found [this article](http://python-notes.curiousefficiency.org/en/latest/python_concepts/import_traps.html) that helps understand how that is an issue. I went into

```
/home/eoziolor/.conda/envs/pybed_phgenome/lib/python3.6/site-packages/pybedtools
mv __init__.py __changedinit__.py
```

* Fucking works. Let's try it again.

```
conda install pysam
conda install -c bioconda pybedtools
conda install -c conda-forge intervaltree
conda install -c conda-forge statistics 
conda install cython
conda install -c bioconda bedtools htslib
```

July 31, 2018
===

* Ok that's a bust.

* Bill was able to install the dependencies in the bio3 package, so I am running the script below again

```
#!/bin/bash -l

#SBATCH -J runarks1
#SBATCH -o runarks1-%j.o
#SBATCH -e runarks1-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=2-00:00
#SBATCH --no-requeue
#SBATCH -p high

export PATH=/home/eoziolor/program/tigmint/bin:$PATH
export PATH=/home/eoziolor/program/arks/Examples:$PATH
export PATH=/home/eoziolor/program/arks/Arks:$PATH

module load bio3

cd /home/eoziolor/phgenome/data/tigarks/arks1/

#files
my_fasta=supernova
my_reads=barcoded

#code
arks-make2 arks-tigmint \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=5 \
e=10000 \
r=0.05 \
l=5 \
z=250 \
k=42 \
threads=16 \
t=16
```

* This actually yields a lower assembly than the original. I think it's mostly because of scaffolding errors being fixed from previous pipeline. Let's re-run

### ARKS run 2

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks1/supernova.tigmint_c5_m50-10000_k42_r0.05_e10000_z250_l5_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks2/arks1.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks2/
```
* Changing kmer size to 30 (default) and pushing e from 10 to 15k

```
#!/bin/bash -l

#SBATCH -J runarks2
#SBATCH -o runarks2-%j.o
#SBATCH -e runarks2-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks2/

#files
my_fasta=arks1
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=5 \
e=15000 \
r=0.05 \
l=5 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 3

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks2/arks1_c5_m50-10000_k30_r0.05_e15000_z250_l5_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks3/arks2.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks3/
```
* Changing e value to 20k

```
#!/bin/bash -l

#SBATCH -J runarks3
#SBATCH -o runarks3-%j.o
#SBATCH -e runarks3-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks3/

#files
my_fasta=arks2
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=5 \
e=20000 \
r=0.05 \
l=5 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 4

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks3/arks2_c5_m50-10000_k30_r0.05_e20000_z250_l5_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks4/arks3.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks4/
```
* Changing e value to 25k

```
#!/bin/bash -l

#SBATCH -J runarks4
#SBATCH -o runarks4-%j.o
#SBATCH -e runarks4-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks4/

#files
my_fasta=arks3
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=5 \
e=25000 \
r=0.05 \
l=5 \
z=250 \
k=30 \
threads=16 
```

August 1, 2018
===

### ARKS run 5

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks4/arks3_c5_m50-10000_k30_r0.05_e25000_z250_l5_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks5/arks4.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks5/
```
* Changing e value to 35k
* Changing c and l to 3 (suggested as acceptable in ARCS paper)

```
#!/bin/bash -l

#SBATCH -J runarks5
#SBATCH -o runarks5-%j.o
#SBATCH -e runarks5-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks5/

#files
my_fasta=arks4
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=35000 \
r=0.05 \
l=3 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 6

* Ok I feel like we are running into the limit here, let's loosen the beast

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks5/arks4_c3_m50-10000_k30_r0.05_e35000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks6/arks5.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks6/
```
* Changing e value to 10k
* Changing r to 0.1


```
#!/bin/bash -l

#SBATCH -J runarks6
#SBATCH -o runarks6-%j.o
#SBATCH -e runarks6-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks6/

#files
my_fasta=arks5
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=10000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 7

* LOOOSEN ITTTT

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks6/arks5_c3_m50-10000_k30_r0.1_e10000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks7/arks6.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks7/
```
* Changing e value to 30k
* Changing a to 0.9


```
#!/bin/bash -l

#SBATCH -J runarks7
#SBATCH -o runarks7-%j.o
#SBATCH -e runarks7-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks7/

#files
my_fasta=arks6
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
c=3 \
e=30000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16 
```
### ARKS run 8

* Beast has been unleashed, let's iterate

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks7/arks6_c3_m50-10000_k30_r0.1_e30000_z250_l3_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks8/arks7.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks8/
```
* Changing e value to 40k
* keeping a to 0.9


```
#!/bin/bash -l

#SBATCH -J runarks8
#SBATCH -o runarks8-%j.o
#SBATCH -e runarks8-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks8/

#files
my_fasta=arks7
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
c=3 \
e=40000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16 
```

Aug 2, 2018
===

### ARKS run 9

* Beast has been unleashed, let's iterate

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks8/arks7_c3_m50-10000_k30_r0.1_e40000_z250_l3_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks9/arks8.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks9/
```
* Changing e value to 50k
* Change c and l back to 5 for the longer scaffolds


```
#!/bin/bash -l

#SBATCH -J runarks9
#SBATCH -o runarks9-%j.o
#SBATCH -e runarks9-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks9/

#files
my_fasta=arks8
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
c=5 \
e=50000 \
r=0.1 \
l=5 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 10

* Beast has been unleashed, let's iterate

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks9/arks8_c5_m50-10000_k30_r0.1_e50000_z250_l5_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks10/arks9.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks10/
```
* Changing e value to 60k
* put r at 0.05 for the largest scaffolds

```
#!/bin/bash -l

#SBATCH -J runarks10
#SBATCH -o runarks10-%j.o
#SBATCH -e runarks10-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks10/

#files
my_fasta=arks9
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
c=5 \
e=60000 \
r=0.1 \
l=5 \
z=250 \
k=30 \
threads=16 
```
### ARKS run 11

* Beast has been unleashed, let's iterate

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks10/arks9_c5_m50-10000_k30_r0.05_e60000_z250_l5_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks11/arks10.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks11/
```
* Changing e value to 10k
* Bringing a back down to 0.5

```
#!/bin/bash -l

#SBATCH -J runarks11
#SBATCH -o runarks11-%j.o
#SBATCH -e runarks11-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks11/

#files
my_fasta=arks10
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=5 \
e=10000 \
r=0.1 \
l=5 \
z=250 \
k=30 \
threads=16 
```
### Arks Run 7b

* I've decided to run another set of iterations with relatively tight parameters and see how things go. I didn't loosen parameters until arks7, so now I will repeat the process with the same other parameters, but not reducing "a", which is important for misassembly prevention.

```
mkdir /home/eoziolor/phgenome/data/altarks/arks7b

ln -s /home/eoziolor/phgenome/data/tigarks/arks6/arks5_c3_m50-10000_k30_r0.1_e10000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/altarks/arks7b/arks6.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/altarks/arks7b/
```
* Now running arks with e=30k, but not changing a value.
* returning r to 0.05

```
#!/bin/bash -l

#SBATCH -J runarks7b
#SBATCH -o runarks7b-%j.o
#SBATCH -e runarks7b-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/altarks/arks7b/

#files
my_fasta=arks6
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=30000 \
r=0.05 \
l=3 \
z=250 \
k=30 \
threads=16 
```

Aug 3, 2018
===

### ARKS run 12

* Iterating with loose parameters one more time to see if everything is ready

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks11/arks10_c5_m50-10000_k30_r0.1_e10000_z250_l5_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks12/arks11.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks12/
```
* e is back to 30k
* a is back to 0.9

```
#!/bin/bash -l

#SBATCH -J runarks12
#SBATCH -o runarks12-%j.o
#SBATCH -e runarks12-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=2-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks12/

#files
my_fasta=arks11
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
c=3 \
e=30000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 8b

* It's looking alright, let's continue repeating the pipeline.

```
ln -s /home/eoziolor/phgenome/data/altarks/arks7b/arks6_c3_m50-10000_k30_r0.05_e30000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/altarks/arks8b/arks7b.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/altarks/arks8b/
```
* Changing e value to 40k


```
#!/bin/bash -l

#SBATCH -J runarks8b
#SBATCH -o runarks8b-%j.o
#SBATCH -e runarks8b-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/altarks/arks8b/

#files
my_fasta=arks7b
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=40000 \
r=0.05 \
l=3 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 13

* Iterating with loose parameters one more time to see if everything is ready

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks12/arks11_c3_m50-10000_k30_r0.1_e30000_z250_l3_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks13/arks12.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks13/
```
* e is back to 30k
* a is back to 0.9

```
#!/bin/bash -l

#SBATCH -J runarks13
#SBATCH -o runarks13-%j.o
#SBATCH -e runarks13-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks13/

#files
my_fasta=arks12
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
c=3 \
e=30000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 9b

* Let's iterate

```
ln -s /home/eoziolor/phgenome/data/altarks/arks8b/arks7b_c3_m50-10000_k30_r0.05_e40000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/altarks/arks9b/arks8b.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/altarks/arks9b/
```
* Changing e value to 50k


```
#!/bin/bash -l

#SBATCH -J runarks9b
#SBATCH -o runarks9b-%j.o
#SBATCH -e runarks9b-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/altarks/arks9b/

#files
my_fasta=arks8b
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=50000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16
```
### ARKS run 14

* Iterating with loose parameters one more time to see if everything is ready

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks13/arks12_c3_m50-10000_k30_r0.1_e30000_z250_l3_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks14/arks13.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks14/
```
* e is back to 30k
* a is back to 0.9

```
#!/bin/bash -l

#SBATCH -J runarks14
#SBATCH -o runarks14-%j.o
#SBATCH -e runarks14-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks14/

#files
my_fasta=arks13
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
c=3 \
e=30000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 9b

* Beast has been unleashed, let's iterate

```
ln -s /home/eoziolor/phgenome/data/altarks/arks9b/arks8b_c3_m50-10000_k30_r0.1_e50000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/altarks/arks10b/arks9b.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/altarks/arks10b/
```
* Changing e value to 50k
* Change c and l back to 5 for the longer scaffolds


```
#!/bin/bash -l

#SBATCH -J runarks10b
#SBATCH -o runarks10b-%j.o
#SBATCH -e runarks10b-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/altarks/arks10b/

#files
my_fasta=arks9b
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=50000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16 
```
Aug 4, 2018
===

### ARKS run 15

* Iterating with loose parameters one more time to see if everything is ready

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks14/arks13_c3_m50-10000_k30_r0.1_e30000_z250_l3_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks15/arks14.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks15/
```
* e is back to 30k
* a is back to 0.9

```
#!/bin/bash -l

#SBATCH -J runarks15
#SBATCH -o runarks15-%j.o
#SBATCH -e runarks15-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/tigarks/arks15/

#files
my_fasta=arks14
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.9 \
c=3 \
e=30000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 11b

* Beast has been unleashed, let's iterate

```
ln -s /home/eoziolor/phgenome/data/altarks/arks10b/arks9b_c3_m50-10000_k30_r0.1_e50000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/altarks/arks11b/arks10b.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/altarks/arks11b/
```
* Changing e value to 50k
* Change c and l back to 5 for the longer scaffolds


```
#!/bin/bash -l

#SBATCH -J runarks11b
#SBATCH -o runarks11b-%j.o
#SBATCH -e runarks11b-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/altarks/arks11b/

#files
my_fasta=arks10b
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=10000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16 
```

### ARKS run 16

* Ok this could go on forever, but I have no idea if this is actually building a meaningful genome. I am going to run tigmint again on this one and see the result. I will assemble with conservative outcome

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks15/arks14_c3_m50-10000_k30_r0.1_e30000_z250_l3_a0.9.scaffolds.fa /home/eoziolor/phgenome/data/tigarks/arks16/arks15.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/tigarks/arks16/
```
* e is back to 30k
* a is back to 0.5

```
#!/bin/bash -l

#SBATCH -J runarks16
#SBATCH -o runarks16-%j.o
#SBATCH -e runarks16-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=2-00:00
#SBATCH --no-requeue
#SBATCH -p high

export PATH=/home/eoziolor/program/tigmint/bin:$PATH
export PATH=/home/eoziolor/program/arks/Examples:$PATH
export PATH=/home/eoziolor/program/arks/Arks:$PATH
export PATH=/home/eoziolor/program/links_v1.8.6:$PATH

module load bio3

cd /home/eoziolor/phgenome/data/tigarks/arks16/

#files
my_fasta=arks15
my_reads=barcoded

#code
arks-make2 arks-tigmint \
draft=$my_fasta \
reads=$my_reads \
m=8-10000 \
a=0.5 \
c=3 \
e=10000 \
r=0.1 \
l=3 \
z=250 \
k=30 \
threads=16 \
t=16
```

### ARKS run 12b

* So I think we are maxing out at 0.65 Mb at the strict parameters. One thing that I want to troubleshoot is k. I am going to increase it to 60 as they've done in the paper and see if there is a change.

```
ln -s /home/eoziolor/phgenome/data/altarks/arks11b/arks10b_c3_m50-10000_k30_r0.1_e10000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/altarks/arks12b/arks11b.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/altarks/arks12b/
```
* Changing e value to 30k
* Change k to 60
```
#!/bin/bash -l

#SBATCH -J runarks12b
#SBATCH -o runarks12b-%j.o
#SBATCH -e runarks12b-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/altarks/arks12b/

#files
my_fasta=arks11b
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=10000 \
r=0.1 \
l=3 \
z=250 \
k=60 \
threads=16 
```

Aug 5, 2018
===

### ARKS run 12b

* So I think we are maxing out at 0.65 Mb at the strict parameters. One thing that I want to troubleshoot is k. I am going to increase it to 60 as they've done in the paper and see if there is a change.

```
ln -s /home/eoziolor/phgenome/data/altarks/arks12b/arks11b_c3_m50-10000_k60_r0.1_e10000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/altarks/arks13b/arks12b.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/altarks/arks13b/
```
* Changing e value to 30k
* Keep k to 60
```
#!/bin/bash -l

#SBATCH -J runarks13b
#SBATCH -o runarks13b-%j.o
#SBATCH -e runarks13b-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/altarks/arks13b/

#files
my_fasta=arks12b
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=30000 \
r=0.1 \
l=3 \
z=250 \
k=60 \
threads=16 
```
### ARKS run 13b

* Changing the k to 60 improved assembly when e was at 30. Changing it to 40k to see if that improves longer scaffolds.

```
ln -s /home/eoziolor/phgenome/data/altarks/arks13b/arks12b_c3_m50-10000_k60_r0.1_e30000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/altarks/arks14b/arks13b.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/altarks/arks14b/
```
* Changing e value to 40k
* Keep k to 60
```
#!/bin/bash -l

#SBATCH -J runarks14b
#SBATCH -o runarks14b-%j.o
#SBATCH -e runarks14b-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/altarks/arks14b/

#files
my_fasta=arks13b
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=40000 \
r=0.1 \
l=3 \
z=250 \
k=60 \
threads=16 
```
### ARKS run 15b

* Changing the k to 60 improved assembly when e was at 30. Changing it back to 30k to iterate.

```
ln -s /home/eoziolor/phgenome/data/altarks/arks14b/arks13b_c3_m50-10000_k60_r0.1_e40000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/altarks/arks15b/arks14b.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/altarks/arks15b/
```
* Changing e value to 30k
* Keep k to 60
```
#!/bin/bash -l

#SBATCH -J runarks15b
#SBATCH -o runarks15b-%j.o
#SBATCH -e runarks15b-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/altarks/arks15b/

#files
my_fasta=arks14b
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=30000 \
r=0.1 \
l=3 \
z=250 \
k=60 \
threads=16 
```
### ARKS run 16b

* Changing the k to 60 improved assembly when e was at 30. Changing it back to 30k to iterate.

```
ln -s /home/eoziolor/phgenome/data/altarks/arks15b/arks14b_c3_m50-10000_k60_r0.1_e30000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/altarks/arks16b/arks15b.fa
ln -s /home/eoziolor/phgenome/data/raw/NewFastq/outs/barcoded.fastq.gz /home/eoziolor/phgenome/data/altarks/arks16b/
```

* Keeping e value to 30k
* Changing k value to 100 (max)

```
#!/bin/bash -l

#SBATCH -J runarks16b
#SBATCH -o runarks16b-%j.o
#SBATCH -e runarks16b-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

cd /home/eoziolor/phgenome/data/altarks/arks16b/

#files
my_fasta=arks15b
my_reads=barcoded

#code
arks-make2 arks \
draft=$my_fasta \
reads=$my_reads \
m=50-10000 \
a=0.5 \
c=3 \
e=30000 \
r=0.1 \
l=3 \
z=250 \
k=100 \
threads=16 
```

## Aug. 28, 2018

### Running BUSCO 2.0 on the loosely assembled genome

* Linking the genome to a new folder for ease of access

```
ln -s /home/eoziolor/phgenome/data/tigarks/arks16/arks15.tigmint_c3_m8-10000_k30_r0.1_e10000_z250_l3_a0.5.scaffolds.fa /home/eoziolor/phgenome/data/genome/phgenome_arks.fasta
```

* Downloading the eukaryota specific lineage set for busco

```
mkdir /home/eoziolor/phgenome/data/busco/
cd /home/eoziolor/phgenome/data/busco/

curl -O https://busco.ezlab.org/datasets/eukaryota_odb9.tar.gz
tar -xvzf eukaryota_odb9.tar.gz
```

* Actually instead I will download the actinopterygii specific dataset as per the documentation from BUSCO

```
wget http://busco.ezlab.org/v2/datasets/actinopterygii_odb9.tar.gz
tar -xvzf actinopterygii_odb9.tar.gz 
```

* Copying augustus directory into my own files

```
cp -r /share/apps/augustus-3.2.3/config /home/eoziolor/phgenome/data/busco/
```

* BUSCO run attempt 1

```
#!/bin/bash -l

#SBATCH -J arks_busco
#SBATCH -o arks_busco-%j.o
#SBATCH -e arks_busco-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=2-00:00
#SBATCH --no-requeue
#SBATCH -p high
#SBATCH -D /home/eoziolor/phgenome/data/busco/

module load busco
module load python3
module load bio3
export AUGUSTUS_CONFIG_PATH=/home/eoziolor/phgenome/data/busco/config/

my_run=/share/apps/busco-v2/BUSCO.py
my_lineage=/home/eoziolor/phgenome/data/busco/actinopterygii_odb9
my_genome=/home/eoziolor/phgenome/data/genome/phgenome_arks.fasta
my_out=arks_busco_actino


python $my_run \
-i $my_genome \
-o $my_out \
-l $my_lineage \
-m genome \
-c 16 \
-sp zebrafish
```

* Running BUSCO on metazoa as well per Andrew's request

```
curl -O https://busco.ezlab.org/datasets/metazoa_odb9.tar.gz
tar -xvzf metazoa_odb9.tar.gz 
```
* BUSCO run metazoa

```
#!/bin/bash -l

#SBATCH -J arks_busco_met
#SBATCH -o arks_busco_met-%j.o
#SBATCH -e arks_busco_met-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=2-00:00
#SBATCH --no-requeue
#SBATCH -p high
#SBATCH -D /home/eoziolor/phgenome/data/busco/

module load busco
module load python3
module load bio3
export AUGUSTUS_CONFIG_PATH=/home/eoziolor/phgenome/data/busco/config/

my_run=/share/apps/busco-v2/BUSCO.py
my_lineage=/home/eoziolor/phgenome/data/busco/metazoa_odb9
my_genome=/home/eoziolor/phgenome/data/genome/phgenome_arks.fasta
my_out=arks_busco_met


python $my_run \
-i $my_genome \
-o $my_out \
-l $my_lineage \
-m genome \
-c 16 \
-sp zebrafish
```


Aug 30, 2018
===
* Downloaded the transcriptome from Tony to run for busco
* need to remove all forward slashes

```
cat isoseq_flnc.fasta | sed 's/\//\_/g' > flnc_new.fasta
```

* running on both the full length transcripts and full transcriptome

```
#!/bin/bash -l

#SBATCH -J arks_busco_trall_met
#SBATCH -o arks_busco_trall_met-%j.o
#SBATCH -e arks_busco_trall_met-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high
#SBATCH -D /home/eoziolor/phgenome/data/transcriptome/

module load busco
module load python3
module load bio3
export AUGUSTUS_CONFIG_PATH=/home/eoziolor/phgenome/data/busco/config/

my_run=/share/apps/busco-v2/BUSCO.py
my_lineage=/home/eoziolor/phgenome/data/busco/metazoa_odb9
my_genome=/home/eoziolor/phgenome/data/transcriptome/draft_new.fasta
my_out=arks_busco_trall_met


python $my_run \
-i $my_genome \
-o $my_out \
-l $my_lineage \
-m transcriptome \
-c 16 \
-sp zebrafish
```

```
#!/bin/bash -l

#SBATCH -J arks_busco_flnc_met
#SBATCH -o arks_busco_flnc_met-%j.o
#SBATCH -e arks_busco_flnc_met-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high
#SBATCH -D /home/eoziolor/phgenome/data/transcriptome/

module load busco
module load python3
module load bio3
export AUGUSTUS_CONFIG_PATH=/home/eoziolor/phgenome/data/busco/config/

my_run=/share/apps/busco-v2/BUSCO.py
my_lineage=/home/eoziolor/phgenome/data/busco/metazoa_odb9
my_genome=/home/eoziolor/phgenome/data/transcriptome/flnc_new.fasta
my_out=arks_busco_flnc_met


python $my_run \
-i $my_genome \
-o $my_out \
-l $my_lineage \
-m transcriptome \
-c 16 \
-sp zebrafish
```

Sept. 4, 2018
===
* Trying out blobology

```
git clone git://github.com/blaxterlab/blobology.git
nano ~/.bashrc
export PATH=/home/eoziolor/program/blobology:$PATH
```

* Ok not that's bullshit for metagenome stuff - never mind

## RepeatMasker
* Was giving me issues for a second, so I had to install Text::Soundex module from cpan

```
cpan install Text::Soundex
export PERL5LIB=/home/eoziolor/perl5/lib/perl5/x86_64-linux-gnu-thread-multi
```

* So apparently the sequence ID is not allowed to be over 50 characters for repeat masker, so I have to shorten the ids for the genome

```
cat /home/eoziolor/phgenome/data/genome/phgenome_arks.fasta | sed "s/,[f|r].*//g" > phgenome_arks_shortid.fasta
```

* Running RepeatMasker

```
#!/bin/bash -l

#SBATCH -J ph_masker
#SBATCH -o ph_masker-%j.o
#SBATCH -e ph_masker-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

my_masker=/home/eoziolor/program/RepeatMasker/RepeatMasker
my_genome=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid.fasta
my_out=/home/eoziolor/phgenome/data/genome/

$my_masker \
-s \
-species "Clupea pallasii" \
-nolow \
-div $my_out \
$my_genome
```

Sept 5, 2018
===

## Repeat Modeler

* RepeatMasker masked very few things in the genome (just repeats and no transposable elements).
* Now it's the job for RepeatModeler to find regions that look like they are insertions.

* Creating a database for cpallasii

```
#!/bin/bash -l

#SBATCH -J ph_db
#SBATCH -o ph_db-%j.o
#SBATCH -e ph_db-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high
#SBATCH -D /home/eoziolor/phgenome/data/repeat/

source ~/.bashrc

my_db=/home/eoziolor/program/RepeatModeler-open-1.0.11/BuildDatabase
my_phgenome=/home/eoziolor/phgenome/data/genome/phgenome_arks_masked.fasta

$my_db \
-name cpallasii \
-engine ncbi \
$my_phgenome
```

* Running RepeatModeler

```#!/bin/bash -l

#SBATCH -J ph_model
#SBATCH -o ph_model-%j.o
#SBATCH -e ph_model-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high
#SBATCH -D /home/eoziolor/phgenome/data/repeat/

source ~/.bashrc

my_model=/home/eoziolor/program/RepeatModeler-open-1.0.11/RepeatModeler
my_db=/home/eoziolor/phgenome/data/repeat/cpallasii

$my_model \
-engine ncbi \
-pa 15 \
-database $my_db
```
Sept 6, 2018
===

* I have to re-run RepeatModeler as it timed out

```
#!/bin/bash -l

#SBATCH -J ph_model
#SBATCH -o ph_model-%j.o
#SBATCH -e ph_model-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=2-00:00
#SBATCH --no-requeue
#SBATCH -p high
#SBATCH -D /home/eoziolor/phgenome/data/repeat/

source ~/.bashrc

my_model=/home/eoziolor/program/RepeatModeler-open-1.0.11/RepeatModeler
my_db=/home/eoziolor/phgenome/data/repeat/cpallasii
my_olddir=/home/eoziolor/phgenome/data/repeat/RM_27835.WedSep51440122018/

$my_model \
-engine ncbi \
-pa 15 \
-recoverDir $my_olddir \
-database $my_db
```

Sept 12, 2018
===
* Re-running RepeatMasker with -lib from the RepeatModeler run
* Can't use -species tag with lib
* found these direcitons [here](https://github.com/umd-byob/presentations/tree/master/2015/0324-RepeatMasker-RepeatModeler)

```
#!/bin/bash -l

#SBATCH -J ph_masker
#SBATCH -o ph_masker-%j.o
#SBATCH -e ph_masker-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high

source ~/.bashrc

my_masker=/home/eoziolor/program/RepeatMasker/RepeatMasker
my_genome=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid.fasta
my_out=/home/eoziolor/phgenome/data/genome/
my_lib=/home/eoziolor/phgenome/data/repeat/RM_27835.WedSep51440122018/consensi.fa.classified


$my_masker \
-s \
-lib $my_lib \
-nolow \
-div $my_out \
$my_genome
```

Oct 18, 2018
===

# Busco on Tony's new transcriptome

* Removing forward slashes from file

```{bash}
cat all.hq.fasta | sed 's/\//\_/g' > all.hq.new.fasta
```

* running job

```{bash}
#!/bin/bash -l

#SBATCH -J busco_all_met
#SBATCH -o busco_all_met-%j.o
#SBATCH -e busco_all_met-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high
#SBATCH -D /home/eoziolor/phgenome/data/transcriptome/

module load busco
module load python3
module load bio3
export AUGUSTUS_CONFIG_PATH=/home/eoziolor/phgenome/data/busco/config/

my_run=/share/apps/busco-v2/BUSCO.py
my_lineage=/home/eoziolor/phgenome/data/busco/metazoa_odb9
my_genome=/home/eoziolor/phgenome/data/transcriptome/all.hq.new.fasta
my_out=busco_all_met


python $my_run \
-i $my_genome \
-o $my_out \
-l $my_lineage \
-m transcriptome \
-c 16 \
-sp zebrafish
```

* Combining hq and lq transcripts and running busco

```{bash}
cat all.hq.fasta all.lq.fasta | sed 's/\//\_/g' > combined.tr.fasta
```

```{bash}
#!/bin/bash -l

#SBATCH -J busco_combo_met
#SBATCH -o busco_combo_met-%j.o
#SBATCH -e busco_combo_met-%j.o
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --mem=60000
#SBATCH --time=1-00:00
#SBATCH --no-requeue
#SBATCH -p high
#SBATCH -D /home/eoziolor/phgenome/data/transcriptome/

module load busco
module load python3
module load bio3
export AUGUSTUS_CONFIG_PATH=/home/eoziolor/phgenome/data/busco/config/

my_run=/share/apps/busco-v2/BUSCO.py
my_lineage=/home/eoziolor/phgenome/data/busco/metazoa_odb9
my_genome=/home/eoziolor/phgenome/data/transcriptome/combined.tr.fasta
my_out=busco_combo_met


python $my_run \
-i $my_genome \
-o $my_out \
-l $my_lineage \
-m transcriptome \
-c 16 \
-sp zebrafish
```

Nov 9, 2018
===

## HiC reads
* Moved HiC reads from Tony's hard drive with

```{bash}
scp -P 2022 /Volumes/HerringProjectTG/HiC_raw_data/Cp_HiC/* farm:/group/awhitehegrp/HiC_seq/Herring_raw_data/
```

* Creating soft link

```{bash}
ln -s /group/awhitehegrp/HiC_seq/Herring_raw_data/Cp_HiC_USPD16090393_HT7WTCCXY_L7_1.fq.gz /home/eoziolor/phgenome/data/hic/raw/herring_hic_1.fastq.gz
ln -s /group/awhitehegrp/HiC_seq/Herring_raw_data/Cp_HiC_USPD16090393_HT7WTCCXY_L7_2.fq.gz /home/eoziolor/phgenome/data/hic/raw/herring_hic_2.fastq.gz

ln -s /group/awhitehegrp/HiC_seq/Herring_raw_data/MD5.txt /home/eoziolor/phgenome/data/hic/raw/MD5.txt
```

* Checking MD5sum

```
cat MD5.txt | md5sum -c - > checkmd5.txt
```

* Running fastqc on reads

```
module load bio3
fastqc *.fq.gz
```

Nov 13, 2018
===

* Ran multiqc on files

```
multiqc .
```

* Moving Arima pipeline files into farm

```
scp -P 2022 ~/phgenome_post/scripts/*.pl farm:/home/eoziolor/phgenome/scripts/hic/
```

## Mapping HiC reads

About to use a pipeline adapted from [Arima](https://github.com/ArimaGenomics/mapping_pipeline/blob/master/Arima_Mapping_UserGuide_A160146_v00.pdf) to map HiC reads to the genome produced from 10x + ARKS

Code:

```{bash}
#!/bin/bash

#SBATCH -J hic_map
#SBATCH -o hic_map_%j.o
#SBATCH -e hic_map_%j.o
#SBATCH --mem=60000
#SBATCH -t 2-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

SRA="herring_hic"
LABEL="herring_genome"
BWA="/home/eoziolor/program/bwa-0.7.17/bwa"
SAMTOOLS="/home/eoziolor/program/samtools-1.9/samtools"
IN_DIR="/home/eoziolor/phgenome/data/hic/raw/"
REF="/home/eoziolor/phgenome/genome/phgenome_arks_shortid.fasta"
FAIDX="$REF.fai"
RAW_DIR="/home/eoziolor/phgenome/data/hic/align/"
FILT_DIR="/home/eoziolor/phgenome/data/hic/align/filter/"
FILTER="/home/eoziolor/phgenome/scripts/hic/filter_five_end.pl"
COMBINER="/home/eoziolor/phgenome/scripts/hic/two_read_bam_combiner.pl"
STATS="/home/eoziolor/phgenome/scripts/hic/get_stats.pl"
PICARD="/home/eoziolor/program/picard.jar"
TMP_DIR="/home/eoziolor/phgenome/data/hic/temp/"
PAIR_DIR="/home/eoziolor/phgenome/data/hic/pair/"
REP_DIR="/home/eoziolor/phgenome/data/hic/dedup/"
MERGE_DIR="/home/eoziolor/phgenome/data/hic/merged/"
MAPQ_FILTER=10

echo "### Step 0: Check output directories exist & create them as needed"
[ -d $RAW_DIR ] || mkdir -p $RAW_DIR
[ -d $FILT_DIR ] || mkdir -p $FILT_DIR
[ -d $TMP_DIR ] || mkdir -p $TMP_DIR
[ -d $PAIR_DIR ] || mkdir -p $PAIR_DIR
[ -d $REP_DIR ] || mkdir -p $REP_DIR
[ -d $MERGE_DIR ] || mkdir -p $MERGE_DIR

echo "### Step 1.A: FASTQ to BAM (1st)"
$BWA mem -t 23 -B 8 $REF $IN_DIR/$SRA\_1.fastq.gz | $SAMTOOLS view -Sb - > $RAW_DIR/$SRA\_1.bam

echo "### Step 1.B: FASTQ to BAM (2nd)"
$BWA mem -t 23 -B 8 $REF $IN_DIR/$SRA\_2.fastq.gz | $SAMTOOLS view -Sb - > $RAW_DIR/$SRA\_2.bam

echo "### Step 2.A: Filter 5' end (1st)"
$SAMTOOLS view -h $RAW_DIR/$SRA\_1.bam | perl $FILTER | $SAMTOOLS view -Sb - > $FILT_DIR/$SRA\_1.bam

echo "### Step 2.B: Filter 5' end (2nd)"
$SAMTOOLS view -h $RAW_DIR/$SRA\_2.bam | perl $FILTER | $SAMTOOLS view -Sb - > $FILT_DIR/$SRA\_2.bam

echo "### Step 3A: Pair reads & mapping quality filter"
perl $COMBINER $FILT_DIR/$SRA\_1.bam $FILT_DIR/$SRA\_2.bam $SAMTOOLS $MAPQ_FILTER | $SAMTOOLS view -bS -t $FAIDX - | $SAMTOOLS sort -o $TMP_DIR/$SRA.bam -

echo "### Step 3.B: Add read group"
java -Xmx20g -jar $PICARD AddOrReplaceReadGroups INPUT=$TMP_DIR/$SRA.bam OUTPUT=$PAIR_DIR/$SRA.bam ID=$SRA LB=$SRA SM=$LABEL PL=ILLUMINA PU=none

###############################################################################################################################################################
###                                           How to Accommodate Technical Replicates                                                                       ###
### This pipeline is currently built for processing a single sample with one read1 and read2 fastq file.                                                    ###
### Technical replicates (eg. one library split across multiple lanes) should be merged before running the MarkDuplicates command.                          ###
### If this step is run, the names and locations of input files to subsequent steps will need to be modified in order for subsequent steps to run correctly.###          
### The code below is an example of how to merge technical replicates.                                                                                      ###
###############################################################################################################################################################
#	REP_NUM=X #number of the technical replicate set e.g. 1
#	REP_LABEL=$LABEL\_rep$REP_NUM
#	INPUTS_TECH_REPS=('bash' 'array' 'of' 'bams' 'from' 'replicates') #BAM files you want combined as technical replicates
#   example bash array - INPUTS_TECH_REPS=('INPUT=A.L1.bam' 'INPUT=A.L2.bam' 'INPUT=A.L3.bam')
#	java -Xms4G -Xmx4G -jar $PICARD MergeSamFiles $INPUTS_TECH_REPS OUTPUT=$TMP_DIR/$REP_LABEL.bam USE_THREADING=TRUE ASSUME_SORTED=TRUE VALIDATION_STRINGENCY=LENIENT

echo "### Step 4: Mark duplicates"
java -Xms60G -XX:-UseGCOverheadLimit -Xmx60G -jar $PICARD MarkDuplicates INPUT=$PAIR_DIR/$SRA.bam OUTPUT=$REP_DIR/$REP_LABEL.bam METRICS_FILE=$REP_DIR/metrics.$REP_LABEL.txt TMP_DIR=$TMP_DIR ASSUME_SORTED=TRUE VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=TRUE

$SAMTOOLS index $REP_DIR/$REP_LABEL.bam 

perl $STATS $REP_DIR/$REP_LABEL.bam > $REP_DIR/$REP_LABEL.bam.stats

echo "Finished Mapping Pipeline through Duplicate Removal"
```

* Indexing genome

```
/home/eoziolor/program/samtools-1.9/samtools faidx phgenome_arks_shortid.fasta
```

* More indexing with BWA

```
/home/eoziolor/program/bwa-0.7.17/bwa index phgenome_arks_shortid.fasta
```
* Created a counts file to override dummy enzyme cut site
	* since we used DNase, we will just estimate that the number of cut sites we expect per scaffold are proportional to the length of each scaffold. This file will give the lengths of the scaffolds divided by 2 in two columns

```
cat phgenome_arks_shortid.fasta.fai | awk '{OFS="\t"}{s=$2/2}{print $1,s,s}' > re_counts_iteration_1
```

## Downloading SALSA

* Downloaded scripts

```
git clone https://github.com/machinegun/SALSA.git
```

Nov 14, 2018
===

## Re-running mapping portion
* Step 4 canceled due to node failure, rerunning script from there.
* So EOF marker missing. I think what's happening is that my job got screwed at Step3, which is combining the mapped reads as the combined file is only 4Gb and the total reads are 40Gb. 
	* So I will re-run Steps 3 and 4. 
	* If that fails, I'll rerun everything.
* Changing MapQ filter to 30 to avoid the loss of tons of data
* So the data shows no reads mapped within scaffolds which worries me. I will try with the HiCUP pipeline

HiCUP
===

* Moving program to farm:

```{bash}
scp -P 2022 ~/Downloads/hicup_v0.7.1.tar.gz farm:/home/eoziolor/program/
```
* Unzip

```{bash}
tar -xvzf hicup_v0.7.1.tar.gz
cd hicup_v0.7.1
chmod a+x *
```

Nov 15, 2018
===

# HiCUP cont'd

* Downloaded bowtie2 from [here](https://sourceforge.net/projects/bowtie-bio/files/bowtie2/2.3.4.3/bowtie2-2.3.4.3-source.zip/download), then:

```{bash}
scp -P 2022 ~/Downloads/bowtie2-2.3.4.3-source.zip farm:/home/eoziolor/program/

unzip bowtie2-2.3.4.3-source.zip
cd bowtie2-2.3.4.3
make
```

* Building index for the genome file

```{bash}
bowtie2-build phgenome_arks_shortid.fasta phgenome_arks_shortid
```
## Created a csv for Tony's transcriptome

```{bash}
cat all.hq.fasta | grep "^>" | tr ' ' '\t' | tr ';' '\t' | sed 's/>//g' | sed 's/full_length_coverage=//g' | sed 's/length=//g' | awk '$1=(FNR FS $1)' | awk '{OFS="\t"}{print$2,$1,$4,$2,$2,$3}' | sed 1i'pbid\tpbgene\tlength\trefisoform\trefgene\tfl\_count' | tr '\t' ',' | sed 's/\///g' > all_info.csv
```

Nov 16, 2018
===
* Turning bam to a bed file

```{bash}
#!/bin/bash

#SBATCH -J convert_bamtobed
#SBATCH -o convert_bamtobed_%j.o
#SBATCH -e convert_bamtobed_%j.o
#SBATCH --mem=60000
#SBATCH -t 2-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

HIC=/home/eoziolor/phgenome/data/hic/dedup/herring_genome.bam
BEDTOOLS=/home/eoziolor/program/bedtools2/bin/bamToBed
MED=/home/eoziolor/phgenome/data/hic/dedup/herring_genome.bed
OUT=/home/eoziolor/phgenome/data/hic/final/selfmap_herring.bam

$BEDTOOLS -i $HIC > $MED
sort -k 4 $MED > $OUT
```
* Moving the re_counts_1 file into the directory in which I will re-assemble

```{bash}
ln -s /home/eoziolor/phgenome/data/genome/re_counts_iteration_1 /home/eoziolor/phgenome/data/salsa/selfmap_genome/
```
* Running salsa with self mapped hic reads

```{bash}
#!/bin/bash

#SBATCH -J salsa_self
#SBATCH -o salsa_self_%j.o
#SBATCH -e salsa_self_%j.o
#SBATCH --mem=60000
#SBATCH -t 6-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

genome=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid.fasta
fai=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid.fasta.fai
hic=/home/eoziolor/phgenome/data/hic/final/selfmap_herring.bam
salsa=/home/eoziolor/program/SALSA/run_pipeline.py
output=/home/eoziolor/phgenome/data/salsa/selfmap_genome/pherring_hic_self

python $salsa \
-a $genome \
-l $fai \
-b $hic \
-e GATC \
-o $output \
-m yes
```

* Stopped the run and moved the re_counts_iteration_1 into the selfmap_genome directory (__THIS ONE IS IMPORTANT__)

```{bash}
cp re_counts_iteration_1 selfmap_genome
```

* Re-started mapping with the arima pipeline

```{bash}
#!/bin/bash

#SBATCH -J arima_hic_map
#SBATCH -o arima_hic_map_%j.o
#SBATCH -e arima_hic_map_%j.o
#SBATCH --mem=60000
#SBATCH -t 2-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

SRA="herring_hic"
LABEL="herring_genome_arima"
BWA="/home/eoziolor/program/bwa-0.7.17/bwa"
SAMTOOLS="/home/eoziolor/program/samtools-1.9/samtools"
IN_DIR="/home/eoziolor/phgenome/data/hic/raw/"
REF="/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid.fasta"
FAIDX="$REF.fai"
RAW_DIR="/home/eoziolor/phgenome/data/hic_arima/align/"
FILT_DIR="/home/eoziolor/phgenome/data/hic_arima/align/filter/"
FILTER="/home/eoziolor/phgenome/scripts/hic/filter_five_end.pl"
COMBINER="/home/eoziolor/phgenome/scripts/hic/two_read_bam_combiner.pl"
STATS="/home/eoziolor/phgenome/scripts/hic/get_stats.pl"
PICARD="/home/eoziolor/program/picard.jar"
TMP_DIR="/home/eoziolor/phgenome/data/hic_arima/temp/"
PAIR_DIR="/home/eoziolor/phgenome/data/hic_arima/pair/"
REP_DIR="/home/eoziolor/phgenome/data/hic_arima/dedup/"
MERGE_DIR="/home/eoziolor/phgenome/data/hic_arima/merged/"
MAPQ_FILTER=10

echo "### Step 0: Check output directories exist & create them as needed"
[ -d $RAW_DIR ] || mkdir -p $RAW_DIR
[ -d $FILT_DIR ] || mkdir -p $FILT_DIR
[ -d $TMP_DIR ] || mkdir -p $TMP_DIR
[ -d $PAIR_DIR ] || mkdir -p $PAIR_DIR
[ -d $REP_DIR ] || mkdir -p $REP_DIR
[ -d $MERGE_DIR ] || mkdir -p $MERGE_DIR

echo "### Step 1.A: FASTQ to BAM (1st)"
$BWA mem -t 23 -B 8 $REF $IN_DIR/$SRA\_1.fq.gz | $SAMTOOLS view -Sb - > $RAW_DIR/$SRA\_1.bam

echo "### Step 1.B: FASTQ to BAM (2nd)"
$BWA mem -t 23 -B 8 $REF $IN_DIR/$SRA\_2.fq.gz | $SAMTOOLS view -Sb - > $RAW_DIR/$SRA\_2.bam

echo "### Step 2.A: Filter 5' end (1st)"
$SAMTOOLS view -h $RAW_DIR/$SRA\_1.bam | perl $FILTER | $SAMTOOLS view -Sb - > $FILT_DIR/$SRA\_1.bam

echo "### Step 2.B: Filter 5' end (2nd)"
$SAMTOOLS view -h $RAW_DIR/$SRA\_2.bam | perl $FILTER | $SAMTOOLS view -Sb - > $FILT_DIR/$SRA\_2.bam

echo "### Step 3A: Pair reads & mapping quality filter"
perl $COMBINER $FILT_DIR/$SRA\_1.bam $FILT_DIR/$SRA\_2.bam $SAMTOOLS $MAPQ_FILTER | $SAMTOOLS view -bS -t $FAIDX - | $SAMTOOLS sort -o $TMP_DIR/$SRA.bam -

echo "### Step 3.B: Add read group"
java -Xmx20g -jar $PICARD AddOrReplaceReadGroups INPUT=$TMP_DIR/$SRA.bam OUTPUT=$PAIR_DIR/$SRA.bam ID=$SRA LB=$SRA SM=$LABEL PL=ILLUMINA PU=none

###############################################################################################################################################################
###                                           How to Accommodate Technical Replicates                                                                       ###
### This pipeline is currently built for processing a single sample with one read1 and read2 fastq file.                                                    ###
### Technical replicates (eg. one library split across multiple lanes) should be merged before running the MarkDuplicates command.                          ###
### If this step is run, the names and locations of input files to subsequent steps will need to be modified in order for subsequent steps to run correctly.###          
### The code below is an example of how to merge technical replicates.                                                                                      ###
###############################################################################################################################################################
#	REP_NUM=X #number of the technical replicate set e.g. 1
#	REP_LABEL=$LABEL\_rep$REP_NUM
#	INPUTS_TECH_REPS=('bash' 'array' 'of' 'bams' 'from' 'replicates') #BAM files you want combined as technical replicates
#   example bash array - INPUTS_TECH_REPS=('INPUT=A.L1.bam' 'INPUT=A.L2.bam' 'INPUT=A.L3.bam')
#	java -Xms4G -Xmx4G -jar $PICARD MergeSamFiles $INPUTS_TECH_REPS OUTPUT=$TMP_DIR/$REP_LABEL.bam USE_THREADING=TRUE ASSUME_SORTED=TRUE VALIDATION_STRINGENCY=LENIENT

echo "### Step 4: Mark duplicates"
java -Xms12G -XX:-UseGCOverheadLimit -Xmx12G -jar $PICARD MarkDuplicates INPUT=$PAIR_DIR/$SRA.bam OUTPUT=$REP_DIR/$LABEL.bam METRICS_FILE=$REP_DIR/metrics.$LABEL.txt TMP_DIR=$TMP_DIR ASSUME_SORTED=TRUE VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=TRUE

$SAMTOOLS index $REP_DIR/$LABEL.bam 

perl $STATS $REP_DIR/$LABEL.bam > $REP_DIR/$LABEL.bam.stats

echo "Finished Mapping Pipeline through Duplicate Removal"
```

Nov 17, 2018
===

## Problem with Salsa

* The re_counts_iteration_1 has values that are 4.32423e+9. Changing original file to have round nice numbers

```{bash}
cat phgenome_arks_shortid.fasta.fai | awk '{ORS="\t"}{s=2}{print $1}{printf "%.0f\t", $2/s}{printf "%.0f\n", $2/s}' | tr ' ' '\t' > re_counts_iteration_1
cp re_counts_iteration_1 pherring_hic_self/
```

Nov 19, 2018
===

## HiC assembly

* there was a problem with the generated bed file having keys with underscores in them. I changed the first column to not have those underscores.

```{bash}
cat alignment_iteration_1.bed | awk '{print $1}' | sed 's/_1//g' | sed 's/_2//g' > column1.bed
cat alignment_iteration_1.bed | awk '{OFS="\t"}{print $2,$3,$4}' > columns_234.bed
paste -d '\t' column1.bed columns_234.bed >alignment_iteration_1.bed
```

* another problem was that the correct python was not loading, so I added a module loading script together with it.

```{bash}
#!/bin/bash

#SBATCH -J salsa_self
#SBATCH -o salsa_self_%j.o
#SBATCH -e salsa_self_%j.o
#SBATCH --mem=60000
#SBATCH -t 6-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

module load python

genome=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid.fasta
fai=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid.fasta.fai
hic=/home/eoziolor/phgenome/data/hic/final/selfmap_herring.bam
salsa=/home/eoziolor/program/SALSA/run_pipeline.py
output=/home/eoziolor/phgenome/data/salsa/selfmap_genome/pherring_hic_self

python $salsa \
-a $genome \
-l $fai \
-b $hic \
-e GATC \
-o $output \
-m yes
```

Nov 19, 2018
===

## HiC assembly

* there was a problem with the generated bed file having keys with underscores in them. I changed the first column to not have those underscores.

```{bash}
cat alignment_iteration_1.bed | awk '{print $1}' | sed 's/_1//g' | sed 's/_2//g' > column1.bed
cat alignment_iteration_1.bed | awk '{OFS="\t"}{print $2,$3,$4}' > columns_234.bed
paste -d '\t' column1.bed columns_234.bed >alignment_iteration_1.bed
```

* another problem was that the correct python was not loading, so I added a module loading script together with it.

```{bash}
#!/bin/bash

#SBATCH -J salsa_self
#SBATCH -o salsa_self_%j.o
#SBATCH -e salsa_self_%j.o
#SBATCH --mem=60000
#SBATCH -t 6-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

module load python

genome=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid.fasta
fai=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid.fasta.fai
hic=/home/eoziolor/phgenome/data/hic/final/selfmap_herring.bam
salsa=/home/eoziolor/program/SALSA/run_pipeline.py
output=/home/eoziolor/phgenome/data/salsa/selfmap_genome/pherring_hic_self

python $salsa \
-a $genome \
-l $fai \
-b $hic \
-e GATC \
-o $output \
-m yes
```

Nov 20, 2019
===

## HiC with SALSA troubleshooting

* had mislabeled one file, which shouldn't really matter much.

```{bash}
mv self_herring.bam self_herring.bed
```
```{bash}
mv self_herring_arima.bam self_herring_arima.bed
```

* According to Jay G., the comma in the scaffold name could be confusing the script. I'll remove it from the fasta, fai and bed

```{bash}
#Making sure the rest of the genome doesn't have commas to match
cat phgenome_arks_shortid.fasta | grep -v "^>" | grep -c ","
#Removing commas from headers and everything after the comma
cat phgenome_arks_shortid.fasta | sed -E "s/,[0-9]+//g" > phgenome_arks_shortid_2.fasta
#Same for fai file
cat phgenome_arks_shortid.fasta.fai | sed -E "s/,[0-9]+//g" > phgenome_arks_shortid_2.fasta.fai
#Same for bed file
cat selfmap_herring.bed | sed -E 's/,[0-9]+//g' > selfmap_herring_2.bed
#Arima mapped bed
cat selfmap_herring_arima.bed | sed -E 's/,[0-9]+//g' > selfmap_herring_arima_2.bed
```

* Re-running assembly script with new files

```{bash}
#!/bin/bash

#SBATCH -J salsa_self
#SBATCH -o salsa_self_%j.o
#SBATCH -e salsa_self_%j.o
#SBATCH --mem=60000
#SBATCH -t 6-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

module load python

genome=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid_2.fasta
fai=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid_2.fasta.fai
hic=/home/eoziolor/phgenome/data/hic/final/selfmap_herring_2.bed
salsa=/home/eoziolor/program/SALSA/run_pipeline.py
output=/home/eoziolor/phgenome/data/salsa/selfmap_genome/pherring_hic_self

python $salsa \
-a $genome \
-l $fai \
-b $hic \
-e GATC \
-o $output \
-m yes
```

* Arima re-assembly

```{bash}
#!/bin/bash

#SBATCH -J salsa_arima
#SBATCH -o salsa_arima_%j.o
#SBATCH -e salsa_arima_%j.o
#SBATCH --mem=60000
#SBATCH -t 6-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

module load python

genome=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid_2.fasta
fai=/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid_2.fasta.fai
hic=/home/eoziolor/phgenome/data/hic_arima/final/selfmap_herring_arima_2.bed
salsa=/home/eoziolor/program/SALSA/run_pipeline.py
output=/home/eoziolor/phgenome/data/salsa/arima_genome/

python $salsa \
-a $genome \
-l $fai \
-b $hic \
-e GATC \
-o $output \
-m yes
```


* Ok I get the same exact error. I am trying to re-map everything back to the fasta files.

```{bash}
bwa index phgenome_arks_shortid_2.fasta
```

* Re-mapping to the cleaned up genome

```{bash}
#!/bin/bash

#SBATCH -J arima_hic_map
#SBATCH -o arima_hic_map_%j.o
#SBATCH -e arima_hic_map_%j.o
#SBATCH --mem=60000
#SBATCH -t 2-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

SRA="herring_hic"
LABEL="herring_genome_arima"
BWA="/home/eoziolor/program/bwa-0.7.17/bwa"
SAMTOOLS="/home/eoziolor/program/samtools-1.9/samtools"
IN_DIR="/home/eoziolor/phgenome/data/hic/raw/"
REF="/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid_2.fasta"
FAIDX="$REF.fai"
RAW_DIR="/home/eoziolor/phgenome/data/hic_arima/align/"
FILT_DIR="/home/eoziolor/phgenome/data/hic_arima/align/filter/"
FILTER="/home/eoziolor/phgenome/scripts/hic/filter_five_end.pl"
COMBINER="/home/eoziolor/phgenome/scripts/hic/two_read_bam_combiner.pl"
STATS="/home/eoziolor/phgenome/scripts/hic/get_stats.pl"
PICARD="/home/eoziolor/program/picard.jar"
TMP_DIR="/home/eoziolor/phgenome/data/hic_arima/temp/"
PAIR_DIR="/home/eoziolor/phgenome/data/hic_arima/pair/"
REP_DIR="/home/eoziolor/phgenome/data/hic_arima/dedup/"
MERGE_DIR="/home/eoziolor/phgenome/data/hic_arima/merged/"
MAPQ_FILTER=10

echo "### Step 0: Check output directories exist & create them as needed"
[ -d $RAW_DIR ] || mkdir -p $RAW_DIR
[ -d $FILT_DIR ] || mkdir -p $FILT_DIR
[ -d $TMP_DIR ] || mkdir -p $TMP_DIR
[ -d $PAIR_DIR ] || mkdir -p $PAIR_DIR
[ -d $REP_DIR ] || mkdir -p $REP_DIR
[ -d $MERGE_DIR ] || mkdir -p $MERGE_DIR

echo "### Step 1.A: FASTQ to BAM (1st)"
$BWA mem -t 23 -B 8 $REF $IN_DIR/$SRA\_1.fq.gz | $SAMTOOLS view -Sb - > $RAW_DIR/$SRA\_1.bam

echo "### Step 1.B: FASTQ to BAM (2nd)"
$BWA mem -t 23 -B 8 $REF $IN_DIR/$SRA\_2.fq.gz | $SAMTOOLS view -Sb - > $RAW_DIR/$SRA\_2.bam

echo "### Step 2.A: Filter 5' end (1st)"
$SAMTOOLS view -h $RAW_DIR/$SRA\_1.bam | perl $FILTER | $SAMTOOLS view -Sb - > $FILT_DIR/$SRA\_1.bam

echo "### Step 2.B: Filter 5' end (2nd)"
$SAMTOOLS view -h $RAW_DIR/$SRA\_2.bam | perl $FILTER | $SAMTOOLS view -Sb - > $FILT_DIR/$SRA\_2.bam

echo "### Step 3A: Pair reads & mapping quality filter"
perl $COMBINER $FILT_DIR/$SRA\_1.bam $FILT_DIR/$SRA\_2.bam $SAMTOOLS $MAPQ_FILTER | $SAMTOOLS view -bS -t $FAIDX - | $SAMTOOLS sort -o $TMP_DIR/$SRA.bam -

echo "### Step 3.B: Add read group"
java -Xmx20g -jar $PICARD AddOrReplaceReadGroups INPUT=$TMP_DIR/$SRA.bam OUTPUT=$PAIR_DIR/$SRA.bam ID=$SRA LB=$SRA SM=$LABEL PL=ILLUMINA PU=none

###############################################################################################################################################################
###                                           How to Accommodate Technical Replicates                                                                       ###
### This pipeline is currently built for processing a single sample with one read1 and read2 fastq file.                                                    ###
### Technical replicates (eg. one library split across multiple lanes) should be merged before running the MarkDuplicates command.                          ###
### If this step is run, the names and locations of input files to subsequent steps will need to be modified in order for subsequent steps to run correctly.###          
### The code below is an example of how to merge technical replicates.                                                                                      ###
###############################################################################################################################################################
#	REP_NUM=X #number of the technical replicate set e.g. 1
#	REP_LABEL=$LABEL\_rep$REP_NUM
#	INPUTS_TECH_REPS=('bash' 'array' 'of' 'bams' 'from' 'replicates') #BAM files you want combined as technical replicates
#   example bash array - INPUTS_TECH_REPS=('INPUT=A.L1.bam' 'INPUT=A.L2.bam' 'INPUT=A.L3.bam')
#	java -Xms4G -Xmx4G -jar $PICARD MergeSamFiles $INPUTS_TECH_REPS OUTPUT=$TMP_DIR/$REP_LABEL.bam USE_THREADING=TRUE ASSUME_SORTED=TRUE VALIDATION_STRINGENCY=LENIENT

echo "### Step 4: Mark duplicates"
java -Xms12G -XX:-UseGCOverheadLimit -Xmx12G -jar $PICARD MarkDuplicates INPUT=$PAIR_DIR/$SRA.bam OUTPUT=$REP_DIR/$LABEL.bam METRICS_FILE=$REP_DIR/metrics.$LABEL.txt TMP_DIR=$TMP_DIR ASSUME_SORTED=TRUE VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=TRUE

$SAMTOOLS index $REP_DIR/$LABEL.bam 

perl $STATS $REP_DIR/$LABEL.bam > $REP_DIR/$LABEL.bam.stats

echo "Finished Mapping Pipeline through Duplicate Removal"
```

* Also self mapping

```{bash}
#!/bin/bash

#SBATCH -J hic_map
#SBATCH -o hic_map_%j.o
#SBATCH -e hic_map_%j.o
#SBATCH --mem=60000
#SBATCH -t 2-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

SRA="herring_hic"
LABEL="herring_genome"
BWA="/home/eoziolor/program/bwa-0.7.17/bwa"
SAMTOOLS="/home/eoziolor/program/samtools-1.9/samtools"
IN_DIR="/home/eoziolor/phgenome/data/hic/raw/"
REF="/home/eoziolor/phgenome/data/genome/phgenome_arks_shortid_2.fasta"
FAIDX="$REF.fai"
RAW_DIR="/home/eoziolor/phgenome/data/hic/align/"
FILT_DIR="/home/eoziolor/phgenome/data/hic/align/filter/"
FILTER="/home/eoziolor/phgenome/scripts/hic/filter_five_end.pl"
COMBINER="/home/eoziolor/phgenome/scripts/hic/two_read_bam_combiner.pl"
STATS="/home/eoziolor/phgenome/scripts/hic/get_stats.pl"
PICARD="/home/eoziolor/program/picard.jar"
TMP_DIR="/home/eoziolor/phgenome/data/hic/temp/"
PAIR_DIR="/home/eoziolor/phgenome/data/hic/pair/"
REP_DIR="/home/eoziolor/phgenome/data/hic/dedup/"
MERGE_DIR="/home/eoziolor/phgenome/data/hic/merged/"
MAPQ_FILTER=10

echo "### Step 0: Check output directories exist & create them as needed"
#[ -d $RAW_DIR ] || mkdir -p $RAW_DIR
#[ -d $FILT_DIR ] || mkdir -p $FILT_DIR
#[ -d $TMP_DIR ] || mkdir -p $TMP_DIR
#[ -d $PAIR_DIR ] || mkdir -p $PAIR_DIR
#[ -d $REP_DIR ] || mkdir -p $REP_DIR
#[ -d $MERGE_DIR ] || mkdir -p $MERGE_DIR

echo "### Step 1.A: FASTQ to BAM"
paste <(zcat $IN_DIR/$SRA\_1.fq.gz | paste - - - -) \
      <(zcat $IN_DIR/$SRA\_2.fq.gz | paste - - - -) |\
tr '\t' '\n' |\
cutadapt -j 8 --interleaved -a CTGTCTCTTATA -A CTGTCTCTTATA -u 10 -U 10 -q 30 --trim-n --minimum-length 36 - |\
$BWA mem -t 23 -B 8 $REF - | $SAMTOOLS view -Sbq $MAPQ_FILTER |\
$SAMTOOLS view -bS -t $FAIDX - |\
$SAMTOOLS sort -o $RAW_DIR/$SRA\_merged.bam -

#echo "### Step 2.A: Filter 5' end (1st)"
#$SAMTOOLS view -h $RAW_DIR/$SRA\_1.bam | perl $FILTER | $SAMTOOLS view -Sb - > $FILT_DIR/$SRA\_1.bam

#echo "### Step 2.B: Filter 5' end (2nd)"
#$SAMTOOLS view -h $RAW_DIR/$SRA\_2.bam | perl $FILTER | $SAMTOOLS view -Sb - > $FILT_DIR/$SRA\_2.bam

#echo "### Step 3.A: Generate new alignment"
#$BWA aln -t 23 $REF -b1 $FILT_DIR/$SRA\_1.bam > $FILT_DIR/$SRA\_1.sai
#$BWA aln -t 23 $REF -b2 $FILT_DIR/$SRA\_2.bam > $FILT_DIR/$SRA\_2.sai

#echo "### Step 3A: Pair reads & mapping quality filter"
#$BWA sampe $REF $FILT_DIR/$SRA\_1.sai $FILT_DIR/$SRA\_2.sai $FILT_DIR/$SRA\_1.bam $FILT_DIR/$SRA\_2.bam |\
#$SAMTOOLS view -Sq $MAPQ_FILTER - | $SAMTOOLS view -bS -t $FAIDX - | $SAMTOOLS sort -o $TMP_DIR/$SRA.bam -

echo "### Step 3.B: Add read group"
java -Xmx20g -jar $PICARD AddOrReplaceReadGroups INPUT=$RAW_DIR/$SRA\_merged.bam OUTPUT=$PAIR_DIR/$SRA.bam ID=$SRA LB=$SRA SM=$LABEL PL=ILLUMINA PU=none

###############################################################################################################################################################
###                                           How to Accommodate Technical Replicates                                                                       ###
### This pipeline is currently built for processing a single sample with one read1 and read2 fastq file.                                                    ###
### Technical replicates (eg. one library split across multiple lanes) should be merged before running the MarkDuplicates command.                          ###
### If this step is run, the names and locations of input files to subsequent steps will need to be modified in order for subsequent steps to run correctly.###          
### The code below is an example of how to merge technical replicates.                                                                                      ###
###############################################################################################################################################################
#	REP_NUM=X #number of the technical replicate set e.g. 1
#	REP_LABEL=$LABEL\_rep$REP_NUM
#	INPUTS_TECH_REPS=('bash' 'array' 'of' 'bams' 'from' 'replicates') #BAM files you want combined as technical replicates
#   example bash array - INPUTS_TECH_REPS=('INPUT=A.L1.bam' 'INPUT=A.L2.bam' 'INPUT=A.L3.bam')
#	java -Xms4G -Xmx4G -jar $PICARD MergeSamFiles $INPUTS_TECH_REPS OUTPUT=$TMP_DIR/$REP_LABEL.bam USE_THREADING=TRUE ASSUME_SORTED=TRUE VALIDATION_STRINGENCY=LENIENT

echo "### Step 4: Mark duplicates"
java -Xms12G -XX:-UseGCOverheadLimit -Xmx12G -jar $PICARD MarkDuplicates INPUT=$PAIR_DIR/$SRA.bam OUTPUT=$REP_DIR/$LABEL.bam METRICS_FILE=$REP_DIR/metrics.$LABEL.txt TMP_DIR=$TMP_DIR ASSUME_SORTED=TRUE VALIDATION_STRINGENCY=LENIENT REMOVE_DUPLICATES=TRUE

$SAMTOOLS index $REP_DIR/$LABEL.bam 

perl $STATS $REP_DIR/$LABEL.bam > $REP_DIR/$LABEL.bam.stats

echo "Finished Mapping Pipeline through Duplicate Removal"
```

Nov 26, 2018
===

## HiC assembly

* Removing comma from the re-counts-iteration file

```{bash}
cat re_counts_iteration_1 | sed -E 's/,[0-9]+//g' > re_counts_iteration_1_2
mv re_counts_iteration_1_2 re_counts_iteration_1
```

Dec 8, 2018
===

# Running PSMC

* Installed software

```
git clone https://github.com/lh3/psmc.git
cd psmc
make
cd utils
make
```

* Re-aligning raw reads to the new genome

```{bash}
#!/bin/bash -l

#SBATCH -J combo_trimalign
#SBATCH -e combo_trimalign-%j.o
#SBATCH -o combo_trimalign-%j.o
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -t 06-00:00
#SBATCH --mem=60000
#SBATCH -p high
#SBATCH --no-requeue

module load bio3

#Directory and file assignment for each file and program
my_dir=/home/eoziolor/phgenome/data/raw
fq1=$my_dir/PH-Sitka-93_S1_L008_R1_001.fastq.gz
fq2=$my_dir/PH-Sitka-93_S1_L008_R2_001.fastq.gz
my_bwa=/home/eoziolor/program/bwa-0.7.17/bwa
my_sbl=/home/eoziolor/program/samblaster/samblaster
my_sam=/home/eoziolor/program/samtools-1.9/samtools
my_out=/home/eoziolor/phgenome/align/
my_gen=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta
rg=$(echo \@RG\\tID:pws-og\\tPL:Illumina\\tPU:x\\tLB:combined\\tSM:pws-og)
outroot=aligned_pws_og.bam

#Code
paste <(zcat $fq1 | paste - - - -) \
      <(zcat $fq2 | paste - - - -) |\
tr '\t' '\n' |\
cutadapt -j 22 --interleaved -a CTGTCTCTTATA -A CTGTCTCTTATA -u 10 -U 10 -q 30 --trim-n --minimum-length 36 - |\
$my_bwa mem $my_gen -p -R $rg -t 22 - |\
$my_sam view -S -h -u - | \
$my_sam sort -T $my_out/$outroot > $my_out/$outroot
```

* Will use bcftools and vcfutils.pl from bio3

* Creating consensus sequence

```{bash}
#!/bin/bash -l

#SBATCH -J seq_consensus
#SBATCH -e seq_consensus-%j.o
#SBATCH -o seq_consensus-%j.o
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -t 06-00:00
#SBATCH --mem=60000
#SBATCH -p high
#SBATCH --no-requeue

load module bio3

#program
my_sam=/home/eoziolor/program/samtools-1.9/samtools

#files
my_gen=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta
my_align=/home/eoziolor/phgenome/data/align/aligned_pws_og.bam
my_out=/home/eoziolor/phgenome/data/align/consensus_pws_og.fq.gz

#code
$my_sam mpileup -C50 -uf $my_gen $my_align |\
bcftools view -c - |\
vcfutils.pl vcf2fq -d 10 -D 100 |\
gzip > $my_out
```
Dec 10, 2018
===

# Running maker

* using the phgenome_arks_shortid_2.fasta
	* it has simple scaffold names

* Cleaning up any scaffolds that have Ns in them

```{bash}
cd ~/phgenome/data/maker/
sed '/^[^>]/ s/[^AGTC]/N/gi' ../genome/phgenome_arks_shortid_2.fasta >> phgenome_cleanN.fasta
```

* Installing maker

```{bash}
scp -P 2022 ~/Documents/UCD/Projects/Herring\ genome/maker-2.31.10.tgz farm:~/program/
tar -xvzf maker-2.31.10.tgz
cd maker/src/
perl Build.PL
```

* Have to install SNAP manually

```{bash}
curl -O http://korflab.ucdavis.edu/Software/snap-2013-11-29.tar.gz
tar -xvzf snap-2013-11-29.tar.gz
cd snap
sed -i 's/-Werror//g' Makefile*
cd Zoe
sed -i 's/-Werror//g' Makefile*
make
cd ../maker/src/
./Build installdeps
```

* Getting an error

```
Rechecking dependencies to see if installation was successful
Checking prerequisites...
  requires:
    !  Bit::Vector is not installed
    !  Want is not installed
  build_requires:
    !  DBI is not installed
  recommends:
    *  DBD::Pg is not installed
```

Dec 11, 2018
===

# PSMC

* Realized that I'm not aligning to the diploid genome, which is what I need in order to do PSMC.
* Will have to use diploid genome generated by Supernova alone to do this.

```{bash}
#!/bin/bash

#SBATCH -J diploid_fastagen
#SBATCH -o diploid_fastagen_%j.o
#SBATCH -e diploid_fastagen_%j.o
#SBATCH --time=6-00:00
#SBATCH --mem=60000
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue


my_super=/home/eoziolor/program/supernova-2.0.0/supernova
my_out=/home/eoziolor/phgenome/data/assembly3/outs/assembly
my_fasta=/home/eoziolor/phgenome/data/assembly3/fasta/phgenome_diploid

$my_super mkoutput \
--asmdir=$my_out \
--outprefix=$my_fasta \
--style=pseudohap2 \
--minsize=1000 \
--headers=short
```

* For some reason that wasn't creating a verbose output file, so I ran it on a separate node.

* So from reading about it, it might not be necessary for the reference to be "diploid" per se. I just need to be aligning the diploid reads, meaning all possible reads for this individual. So, I might not need to create a phased consensus, but rather just a diploid consensus.

* In short, just keep chugging on with this alignment that I've started.

# Annotation

* Created an NCBI submission for the genome:

__SUB4906111__

* I am changing the genome headers to reflect organism as well.

```{bash}
cat phgenome_arks_shortid_2.fasta | sed 's/>/>Clupea_pallasii_/gi' > phgenome_arks_ncbi.fasta
```

* Well that didn't pass validation because I have 680 scaffolds that are below 200 bases. Let me cut those out.

```{bash}
cat phgenome_arks_ncbi.fasta | head -n -1360 > phgenome_ncbi_long.fasta
cat phgenome_ncbi_long.fasta | tail -n 1 | wc -m
```

* Re-doing the cleanup from yesterday for maker

```{bash}
sed '/^[^>]/ s/[^AGTC]/N/gi' ../genome/phgenome_ncbi_long.fasta >> phgenome_clean.fasta
```

## Maker
* Figured out that maker is already installed on module "bio", so I will just use that.
* Of course it's not as easy as that. It doesn't work:

```{bash}
Clone.c: loadable library and perl binaries are mismatched (got handshake key 0xdb00080, needed 0xde00080)
```

* Ok, there is a maker module on farm with a _slightly_ older verison of maker, just one before the current version. So I will start working with 2.31.9 until the rest is ready.

```{bash}
module load maker
```

* Also renaming the cleaned up version of the post-arks genome. Current name is stupid

```{bash}
mv phgenome_cleanN.fasta phgenome_clean.fasta
```

Starting a 3rd hackmd for this project. This one is becoming slow.
===

Dec 11, 2018 (cont'd)
===

* ok, so apparently maker is really happy working with fasta files for ESTs so I will use those.

```{bash}
cp /group/awhitehegrp/rnaseq/herring/HerringTesticularTranscriptome31545contigs.fasta herring_testes_rna.fasta
cp /group/awhitehegrp/rnaseq/herring/all.hq.fasta herring_pacbio_hq.fasta
cp /group/awhitehegrp/rnaseq/herring/all.lq.fasta herring_pacbio_lq.fasta
ln -s /group/awhitehegrp/rnaseq/herring/HerringHepaticTranscriptome34300contigs.fa herring_liver_rna.fasta
```

## PSMC

* Alignment finished. Now I am running a script to creat a consensus sequence to use for PSMC

```{bash}
#SBATCH -J seq_consensus
#SBATCH -e seq_consensus-%j.o
#SBATCH -o seq_consensus-%j.o
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -t 06-00:00
#SBATCH --mem=60000
#SBATCH -p high
#SBATCH --no-requeue

load module bio3

#program
my_sam=/home/eoziolor/program/samtools-1.9/samtools

#files
my_gen=/home/eoziolor/phgenome/data/genome/phgenome_masked.fasta
my_align=/home/eoziolor/phgenome/data/align/aligned_pws_og.bam
my_out=/home/eoziolor/phgenome/data/align/consensus_pws_og.fq.gz

#code
$my_sam mpileup -C50 -uf $my_gen $my_align |\
bcftools view -c - |\
vcfutils.pl vcf2fq -d 10 -D 100 |\
gzip > $my_out
```
* bcftools throws an error because of the comma in the scaffold name. taking that out.

```{bash}
samtools view -H aligned_pws_og.bam > header.sam
cat header.sam | sed 's/,[0-9]*//g' > new_header.sam
samtools reheader new_header.sam aligned_pws_og.bam > aligned_ss.bam
```

* Doing the same with the genome

```{bash}
cat phgenome_masked.fasta | sed 's/,[0-9]*//g' > phgenome_masked_nocomma.fasta
bwa index phgenome_masked_nocomma.fasta
```

* Throwing in a different error, so I'm using bcftools call instead of view.

```{bash}
#!/bin/bash -l

#SBATCH -J seq_consensus
#SBATCH -e seq_consensus-%j.o
#SBATCH -o seq_consensus-%j.o
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -t 06-00:00
#SBATCH --mem=60000
#SBATCH -p high
#SBATCH --no-requeue

module load bio3

#program
my_sam=/home/eoziolor/program/samtools-1.9/samtools

#files
my_gen=/home/eoziolor/phgenome/data/genome/phgenome_masked_nocomma.fasta
my_align=/home/eoziolor/phgenome/data/align/aligned_ss.bam
my_out=/home/eoziolor/phgenome/data/align/consensus_ss.fq.gz

#code
$my_sam mpileup -C50 -uf $my_gen $my_align |\
bcftools call -c - |\
vcfutils.pl vcf2fq -d 10 -D 100 |\
gzip > $my_out
```

* And it runs properly!

Dec 12, 2018
===

# PSMC

* I will start by running one estimation of demography over time and then when I work that out, I will bootstrap it!

* linking consensus sequence to new directory

```{bash}
#In ~/phgenome/data/psmc/
cp ../align/consensus_ss.fq.gz .
```

* Step 1

```{bash}
~/program/psmc/utils/fq2psmcfa -q20 consensus_ss.fq.gz > diploid.psmcfa
```

* Step 2

```{bash}
~/program/psmc/psmc -N25 -t15 -r5 -p "4+25*2+4+6" -o diploid.psmc diploid.psmcfa
```

* Step 3

```{bash}
~/program/psmc/utils/psmc2history.pl diploid.psmc | ~/program/psmc/utils/history2ms.pl > ms-cmd.sh
```

* Step 4

```{bash}
~/program/psmc/utils/psmc_plot.pl diploid diploid.psmc
```

* Damn, that actually worked!!

## Scaling population size with time

* Finding mutation rate for atlantic herring [here](https://elifesciences.org/articles/23907)
	* 2.0 x 10^-9
* Theta calculated by the algorithm is 0.208700, but I don't know the units of it
* Using 3 years/generation

```{bash}
~/program/psmc/utils/psmc_plot.pl \
-u 2.0e-9 \
-g 3 \
-T "Sitka Sound demography" \
diploid diploid.psmc
```

## Running PSMC with bootstrap

* Ok now that this looks like it's running properly let's try the bootstrap.

* No need to repeat Step 1&2

```{bash}
 ln -s /home/eoziolor/phgenome/data/psmc/consensus_ss.fq.gz bootstrap/
 diploid.psmcfa -> /home/eoziolor/phgenome/data/psmc/diploid.psmcfa
 ln -s /home/eoziolor/phgenome/data/psmc/diploid.psmc bootstrap/
 ```

* Step 2boot

```{bash}
~/program/psmc/utils/splitfa diploid.psmcfa > split.psmcfa
```
* that didn't really do anything because I don't have large chromosomes. I will use the unsplit fasta file

* Step 3boot, going to modify as array

```{bash}
#!/bin/bash -l

#SBATCH -J boot_psmc
#SBATCH --array=1-100
#SBATCH -e boot_psmc%A-%a.o
#SBATCH -o boot_psmc%A-%a.o
#SBATCH -t 01-00:00
#SBATCH --cpus-per-task=1
#SBATCH --mem=8G
#SBATCH -p med
#SBATCH --no-requeue

cd ~/phgenome/data/psmc/bootstrap/

#files and programs
crap=$(echo $SLURM_ARRAY_TASK_ID)
my_psmc=/home/eoziolor/program/psmc/psmc
my_dir=/home/eoziolor/phgenome/data/psmc/bootstrap

#code
$my_psmc -N25 -t15 -r5 -b -p "4+25*2+4+6" \
-o $my_dir/round-$crap.psmc $my_dir/diploid.psmcfa
```

* Step 4boot, combining bootstraps

```{bash}
 cat diploid.psmc round-*.psmc > combined.psmc
```
 
* Step 5boot plotting (3 year generation turnover)

```{bash}
~/program/psmc/utils/psmc_plot.pl \
-u 2.0e-9 \
-g 3 \
-T "Sitka Sound demography" \
combined combined.psmc
```

* So you can see a dip ~ 250 000 years ago, which coinsides with [Wolstonian Glaciacion event](https://en.wikipedia.org/wiki/Wolstonian_Stage). Could be something with the [Pleistocene](https://onlinelibrary.wiley.com/doi/full/10.1111/j.1365-294X.2011.05213.x).
![](https://i.imgur.com/G664CfX.jpg)

# Working on reference genome a bit

* The NCBI assembly came back with contamination of 2 sorts
	* Adaptors found in some sequences
	* And duplication of a bunch of sequences.

* NCBI was able to trim some adaptors, but I have to take care of the rest.

* Starting by removing redundant versions of the genome

```{bash}
rm phgenome_arks_shortid_2.fasta*
rm phgenome_masked.fasta*
mv phgenome_arks_shortid.fasta* pre-masking/
mv *ncbi* ncbi
```

* I am left with this version right now
```
phgenome_ncbi_long.fasta
```

* this version has all scaffolds above 200bp, the fasta is header is by convention > Clupea_pallasii_scaffold#

## To do on the genome
- [x] Arrange scaffolds by size
- [x] Remove contamination and break scaffolds that had adapters in the middle of them
- [ ] Remove duplication
- [ ] re-name scaffolds

### Rearranging scaffolds

* Using bash

```
awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}'  phgenome_ncbi_long.fasta  |\
awk -F '\t' '{printf("%d\t%s\n",length($2),$0);}' |\
sort -nrk 1,1 | cut -f 2- | tr "\t" "\n" > phgenome_ncbi_sorted.fasta
```

### Removing contamination and breaking scaffolds

* Ok NCBI gave me regions of the scaffolds that contain adapters. I will use those regions to mask them to become X character. Then those X characters I will replace with a new line and > Clupea_pallasii_scaffold_new

```{bash}
~/program/bedtools2/bin/bedtools maskfasta -mc X -fi phgenome_ncbi_sorted.fasta -bed adapters.bed -fo phgenome_ncbi_smasked.fasta
```

* Removing Xs and putting new scaffolds in their place. Also replacing leading and lagging Ns with nothing
```{bash}
cat phgenome_ncbi_smasked.fasta | sed -E 's/[X]+/\n>\ Clupea_pallasii_scaffold_new\n/g' | sed -E 's/[N]+$//g' | sed -E 's/^[N]+//g' > phgenome_ncbi_noadapter.fasta
```

### Dealing with small scaffolds with duplicated sequences

* This is a general topic and I think my best way to deal with it is to only retain scaffolds that are >10Kb
	* The points for this is that we will get the majority of the genome from them and those are scaffolds that are not likely containing regions of other scaffolds in them

* To do this, I will do another re-ordering

```{bash}
awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}'  phgenome_ncbi_noadapter.fasta  |\
awk -F '\t' '{printf("%d\t%s\n",length($2),$0);}' |\
sort -nrk 1,1 | cut -f 2- | tr "\t" "\n" > phgenome_ncbi_sortnoadapter.fasta
```

* Have to rename sequence first for new scaffolds to be re-arranged

* Then I will use samtools to create a fai file for this genome

```{bash}
module load bio3
samtools faidx phgenome_ncbi_sortnoadapter.fasta
```

Dec 13, 2018
===

# Genome assembly tinkering

### Removing contamination and breaking scaffolds

* Ok NCBI gave me regions of the scaffolds that contain adapters. I will use those regions to mask them to become X character. Then those X characters I will replace with a new line and > Clupea_pallasii_scaffold_new

```{bash}
~/program/bedtools2/bin/bedtools maskfasta -mc X -fi phgenome_ncbi_sorted.fasta -bed adapters.bed -fo phgenome_ncbi_smasked.fasta
```

* Removing Xs and putting new scaffolds in their place. Also replacing leading and lagging Ns with nothing
```{bash}
cat phgenome_ncbi_smasked.fasta | sed -E 's/[X]+/\n>\ Clupea_pallasii_scaffold_new\n/g' | sed -E 's/[N]+$//g' | sed -E 's/^[N]+//g' > phgenome_ncbi_noadapter.fasta
```

### Dealing with small scaffolds with duplicated sequences

* This is a general topic and I think my best way to deal with it is to only retain scaffolds that are >10Kb
	* The points for this is that we will get the majority of the genome from them and those are scaffolds that are not likely containing regions of other scaffolds in them

* To do this, I will do another re-ordering

```{bash}
awk '/^>/ {printf("%s%s\t",(N>0?"\n":""),$0);N++;next;} {printf("%s",$0);} END {printf("\n");}'  phgenome_ncbi_noadapter.fasta  |\
awk -F '\t' '{printf("%d\t%s\n",length($2),$0);}' |\
sort -nrk 1,1 | cut -f 2- | tr "\t" "\n" > phgenome_ncbi_sortnoadapter.fasta
```

## Renaming scaffolds
* Have to rename sequence first for new scaffolds to be re-arranged

```{bash}
cat phgenome_ncbi_sortnoadapter.fasta |  awk '/^>/{print ">" ++i; next}{print}' | sed 's/>/>Clupea\_pallasii\_scaffold\_/g' > phgenome_ncbi_numbered.fasta
```

## Renaming scaffolds
* Have to rename sequence first for new scaffolds to be re-arranged

```{bash}
cat phgenome_ncbi_sortnoadapter.fasta |  awk '/^>/{print ">" ++i; next}{print}' | sed 's/>/>Clupea\_pallasii\_scaffold\_/g' > phgenome_ncbi_numbered.fasta
```

## Dealing with duplication

* Then I will use samtools to create a fai file for this genome

```{bash}
module load bio3
samtools faidx phgenome_ncbi_numbered.fasta
```

* Checking size of genome represented

```{bash}
cat phgenome_ncbi_numbered.fasta.fai | awk '$2>5000{print $1,$2}' | awk -F ' ' '{sum += $2} END {print sum}'
```

* I am choosing to keep the genome as is and the duplicated regions can be one of 2 things
	* error from assembly
	* duplication due to - fish GWD

* I figure it's more useful if people have more info, rather than less info with less duplication. I think!

# mtDNA

* time to find the mtDNA scaffolds here
* Using blast since there is an existing mtDNA genome on [NCBI](https://www.ncbi.nlm.nih.gov/nuccore/148922558)

```{bash}
makeblastdb -in phgenome_ncbi_numbered.fasta -dbtype nucl
```

* Linearizing mtDNA
```{bash}
sed -e 's/\(^>.*$\)/#\1#/' pherring_mtDNA.fasta | tr -d "\r" | tr -d "\n" | sed -e 's/$/#/' | tr "#" "\n" | sed -e '/^$/d' > new_mtDNA.fasta
```

* Querying
```{bash}
blastn -query /group/awhitehegrp/phgenome/new_mtDNA.fasta -db phgenome_ncbi_numbered.fasta -out mtDNA_match.txt
```

* Two sequences came up with positive hits
	* Clupea_pallasii_scaffold_68391
	* Clupea_pallasii_scaffold_78036
	* Removing these and including the mtDNA at the end of the genome


```{bash}
awk '{ if ((NR>1)&&($0~/^>/)) { printf("\n%s", $0); } else if (NR==1) { printf("%s", $0); } else { printf("\t%s", $0); } }' phgenome_ncbi_numbered.fasta | \
grep -v "Clupea_pallasii_scaffold_68391" - | \
grep -v "Clupea_pallasii_scaffold_78036" - |  \
tr "\t" "\n" | \
awk '/^>/{print ">" ++i; next}{print}' | \
sed 's/>/>Clupea\_pallasii\_scaffold\_/g' | \
cat - /group/awhitehegrp/phgenome/new_mtDNA.fasta > phgenome_ncbi.fasta
```

* linking it to use

```{bash}
ln -s /home/eoziolor/phgenome/data/genome/cleanup/phgenome_ncbi.fasta ../
```

* Submitting correction to NCBI
# Maker

* I have to re-align to the new genome

```{bash}
module load bio3
bwa index phgenome_ncbi.fasta
samtools faidx phgenome_ncbi.fasta
```

* Aligning

```{bash}
#!/bin/bash -l

#SBATCH -J combo_trimalign
#SBATCH -e combo_trimalign-%j.o
#SBATCH -o combo_trimalign-%j.o
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -t 06-00:00
#SBATCH --mem=60000
#SBATCH -p high
#SBATCH --no-requeue

module load bio3

#Directory and file assignment for each file and program
my_dir=/home/eoziolor/phgenome/data/raw
fq1=$my_dir/PH-Sitka-93_S1_L008_R1_001.fastq.gz
fq2=$my_dir/PH-Sitka-93_S1_L008_R2_001.fastq.gz
my_bwa=/home/eoziolor/program/bwa-0.7.17/bwa
my_sbl=/home/eoziolor/program/samblaster/samblaster
my_sam=/home/eoziolor/program/samtools-1.9/samtools
my_out=/home/eoziolor/phgenome/data/align
my_gen=/home/eoziolor/phgenome/data/genome/phgenome_ncbi.fasta
rg=$(echo \@RG\\tID:pws-og\\tPL:Illumina\\tPU:x\\tLB:combined\\tSM:ss-og)
outroot=aligned_ss_og

#Code
paste <(zcat $fq1 | paste - - - -) \
      <(zcat $fq2 | paste - - - -) |\
tr '\t' '\n' |\
cutadapt -j 22 --interleaved -a CTGTCTCTTATA -A CTGTCTCTTATA -u 10 -U 10 -q 30 --trim-n --minimum-length 36 - |\
$my_bwa mem $my_gen -p -R $rg -t 22 - |\
$my_sam view -S -h -u - | \
$my_sam sort -T $my_out/$outroot > $my_out/$outroot\.bam
```

# HiC data

## Juicer

### Installation

* Following installation instructions
```{bash}
mkdir juicer_hic
cd juicer_hic/
mkdir tmp
mkdir fastq
ln -s /group/awhitehegrp/HiC_seq/Herring_raw_data/*1.fq.gz /home/eoziolor/phgenome/data/juicer_hic/fastq/phic_R1.fastq.gz
ln -s /group/awhitehegrp/HiC_seq/Herring_raw_data/*2.fq.gz /home/eoziolor/phgenome/data/juicer_hic/fastq/phic_R2.fastq.gz
cd ..
git clone https://github.com/theaidenlab/juicer.git
ln -s juicer/SLURM/scripts/ scripts
cd scripts
cd ..
mkdir references
cd references/
ln -s ~/phgenome/data/genome/*.fasta* .
mkdir restriction_sites
```

* Running Juicer

```{bash}
my_dir=/home/eoziolor/phgenome/data/juicer_hic
$my_dir/scripts/juicer.sh \
-D $my_dir \
-s none \
-q med \
-l med \
-z $my_dir/references/phgenome_ncbi.fasta \
-p $my_dir/references/phgenome_sizes.txt
```

* Still need to troubleshoot


Dec 14, 2018
===

# Maker

* Making control templates
* Downloading protein databases for pacific herring, atlantic herring, atlantic menhaden, sardines

* Ran maker with CTL file options:

```{bash}
#-----Genome (these are always required)
genome=/home/eoziolor/phgenome/data/genome/phgenome_ncbi.fasta #genome sequence (fasta file or fasta embeded in GFF3 file)
organism_type=eukaryotic #eukaryotic or prokaryotic. Default is eukaryotic

#-----Re-annotation Using MAKER Derived GFF3
maker_gff= #MAKER derived GFF3 file
est_pass=0 #use ESTs in maker_gff: 1 = yes, 0 = no
altest_pass=0 #use alternate organism ESTs in maker_gff: 1 = yes, 0 = no
protein_pass=0 #use protein alignments in maker_gff: 1 = yes, 0 = no
rm_pass=0 #use repeats in maker_gff: 1 = yes, 0 = no
model_pass=0 #use gene models in maker_gff: 1 = yes, 0 = no
pred_pass=0 #use ab-initio predictions in maker_gff: 1 = yes, 0 = no
other_pass=0 #passthrough anyything else in maker_gff: 1 = yes, 0 = no

#-----EST Evidence (for best results provide a file for at least one)
est=/home/eoziolor/phgenome/data/maker/herring_liver_rna.fasta,/home/eoziolor/phgenome/data/maker/herring_pacbio_hq.fasta,/home/eoziolor/phgenome/data/maker/herring_pacbio_lq.fasta,/home/eoziolor/phgenome/data/maker/herring_testes_rna.fasta #set of ESTs or assembled mRNA-seq in fasta format
altest= #EST/cDNA sequence file in fasta format from an alternate organism
est_gff= #aligned ESTs or mRNA-seq from an external GFF3 file
altest_gff= #aligned ESTs from a closly relate species in GFF3 format

#-----Protein Homology Evidence (for best results provide a file for at least one)
protein=/home/eoziolor/phgenome/data/maker/prot_menhaden.fasta,/home/eoziolor/phgenome/data/maker/prot_aherring.fasta,/home/eoziolor/phgenome/data/maker/prot_pherring.fasta,/home/eoziolor/phgenome/data/maker/prot_sardine.fasta #protein sequence file in fasta format (i.e. from mutiple oransisms)
protein_gff=  #aligned protein homology evidence from an external GFF3 file

#-----Repeat Masking (leave values blank to skip repeat masking)
model_org=all #select a model organism for RepBase masking in RepeatMasker
rmlib=/home/eoziolor/phgenome/data/repeat/RM_27835.WedSep51440122018/consensi.fa.classified #provide an organism specific repeat library in fasta format for RepeatMasker
repeat_protein=/share/apps/maker-2.31.10/data/te_proteins.fasta #provide a fasta file of transposable element proteins for RepeatRunner
rm_gff= #pre-identified repeat elements from an external GFF3 file
prok_rm=0 #forces MAKER to repeatmask prokaryotes (no reason to change this), 1 = yes, 0 = no
softmask=1 #use soft-masking rather than hard-masking in BLAST (i.e. seg and dust filtering)

#-----Gene Prediction
snaphmm= #SNAP HMM file
gmhmm= #GeneMark HMM file
augustus_species= #Augustus gene prediction species model
fgenesh_par_file= #FGENESH parameter file
pred_gff= #ab-initio predictions from an external GFF3 file
model_gff= #annotated gene models from an external GFF3 file (annotation pass-through)
est2genome=1 #infer gene predictions directly from ESTs, 1 = yes, 0 = no
protein2genome=0 #infer predictions from protein homology, 1 = yes, 0 = no
trna=0 #find tRNAs with tRNAscan, 1 = yes, 0 = no
snoscan_rrna= #rRNA file to have Snoscan find snoRNAs
unmask=0 #also run ab-initio prediction programs on unmasked sequence, 1 = yes, 0 = no

#-----Other Annotation Feature Types (features MAKER doesn't recognize)
other_gff= #extra features to pass-through to final MAKER generated GFF3 file

#-----External Application Behavior Options
alt_peptide=C #amino acid used to replace non-standard amino acids in BLAST databases
cpus=1 #max number of cpus to use in BLAST and RepeatMasker (not for MPI, leave 1 when using MPI)

#-----MAKER Behavior Options
max_dna_len=100000 #length for dividing up contigs into chunks (increases/decreases memory usage)
min_contig=1 #skip genome contigs below this length (under 10kb are often useless)

pred_flank=200 #flank for extending evidence clusters sent to gene predictors
pred_stats=0 #report AED and QI statistics for all predictions as well as models
AED_threshold=1 #Maximum Annotation Edit Distance allowed (bound by 0 and 1)
min_protein=0 #require at least this many amino acids in predicted proteins
alt_splice=0 #Take extra steps to try and find alternative splicing, 1 = yes, 0 = no
always_complete=0 #extra steps to force start and stop codons, 1 = yes, 0 = no
map_forward=0 #map names and attributes forward from old GFF3 genes, 1 = yes, 0 = no
keep_preds=0 #Concordance threshold to add unsupported gene prediction (bound by 0 and 1)

split_hit=10000 #length for the splitting of hits (expected max intron size for evidence alignments)
single_exon=0 #consider single exon EST evidence when generating annotations, 1 = yes, 0 = no
single_length=250 #min length required for single exon ESTs if 'single_exon is enabled'
correct_est_fusion=0 #limits use of ESTs in annotation to avoid fusion genes

tries=2 #number of times to try a contig if there is a failure for some reason
clean_try=0 #remove all data from previous run before retrying, 1 = yes, 0 = no
clean_up=0 #removes theVoid directory with individual analysis files, 1 = yes, 0 = no
TMP= #specify a directory other than the system default temporary directory for temporary files
```

* Script for running maker is:

```{bash}
#!/bin/bash -l

#SBATCH -J run_maker
#SBATCH -o run_maker-%j.o
#SBATCH -e run_maker-%j.o
#SBATCH -N 1
#SBATCH -n 23
#SBATCH --time=6-00:00
#SBATCH --mem=60000
#SBATCH --no-requeue
#SBATCH -p high

cd /home/eoziolor/phgenome/data/maker

export TMP=/home/eoziolor/phgenome/data/maker/tmp

module load maker

maker -q
```

Dec 18, 2018
===

# HiC assembly

* The HiC assembly didn't work with SALSA, so I am going to try to re-align the data by the standards of Phase Genomics and use Juicebox to manually re-scaffold.

```{bash}
cd /home/eoziolor/phgenome/data
mkdir hic_juice
cd hic_juice
ln -s /group/awhitehegrp/HiC_seq/Herring_raw_data/Cp_HiC_USPD16090393_HT7WTCCXY_L7_1.fq.gz ph_hic_R1.fq.gz
ln -s /group/awhitehegrp/HiC_seq/Herring_raw_data/Cp_HiC_USPD16090393_HT7WTCCXY_L7_2.fq.gz ph_hic_R2.fq.gz
```

* Installed matlock for filtering HiC reads

```{bash}
git clone --recursive https://github.com/phasegenomics/matlock.git matlock ; cd matlock ; make
```

* Installing the QC script for HiC alignment

```{bash}
git clone https://github.com/phasegenomics/bam_to_mate_hist.git && cd bam_to_mate_hist && pip install --user -r requirements.txt && python setup.py install --user
```

* Aligning reads and QCing them (filtering option is there JIC)

```{bash}
#!/bin/bash

#SBATCH -J hic_juice_align
#SBATCH -o hic_juice_align_%j.o
#SBATCH -e hic_juice_align_%j.o
#SBATCH --mem=60000
#SBATCH -t 2-00:00
#SBATCH -N 1
#SBATCH -n 23
#SBATCH -p high
#SBATCH --no-requeue

#files and programs
BWA="/home/eoziolor/program/bwa-0.7.17/bwa"
SAMTOOLS="/home/eoziolor/program/samtools-1.9/samtools"
SAMBLASTER="/home/eoziolor/program/samblaster/samblaster"
hic1="/home/eoziolor/phgenome/data/hic_juice/ph_hic_R1.fq.gz"
hic2="/home/eoziolor/phgenome/data/hic_juice/ph_hic_R2.fq.gz"
REF="/home/eoziolor/phgenome/data/genome/phgenome_ncbi.fasta"
align_dir="/home/eoziolor/phgenome/data/hic_juice/align"
my_out="ph_hic_aligned.bam"
my_mat="/home/eoziolor/program/matlock/bin/matlock"
my_qc_file="ph_hic_qc"
my_filt="ph_hic_filtered.bam"
my_qc="/home/eoziolor/program/bam_to_mate_hist/bam_to_mate_hist.py"


#alignment and deduplication
$BWA mem -t 22 -5SP $REF $hic1 $hic2 | $SAMBLASTER | samtools view -S -h -b -F 2316 > $align_dir/$my_out &&

#QC of aligned reads
$my_qc -b $align_dir/$my_out -r -o $my_qc_file

#filtering of aligned reads
#$my_mat bamfilt -i $align_dir/$my_out -o $align_dir/$my_filt
```

